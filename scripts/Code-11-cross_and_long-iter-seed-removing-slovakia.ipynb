{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f67a47d9-8778-4db5-94be-173846cbd6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from matplotlib.lines import Line2D\n",
    "from scipy.stats import pearsonr, gaussian_kde, linregress, ttest_ind, sem, zscore\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import percentileofscore\n",
    "from sklearn.utils.validation import check_random_state\n",
    "from math import factorial\n",
    "from more_itertools import distinct_permutations\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import linregress\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import KFold, ParameterGrid, train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import warnings\n",
    "import random\n",
    "#from torch.utils.data import SubsetRandomSampler\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from statsmodels.stats.diagnostic import linear_harvey_collier\n",
    "from scipy.stats import chi2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from colorama import Fore, Style, init\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from collections import Counter\n",
    "\n",
    "from statsmodels.stats.diagnostic import linear_harvey_collier\n",
    "from scipy.stats import chi2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from colorama import Fore, Style, init\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fabecce3-4309-4dda-8aea-2e7a0ecfa21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2\n",
    "\n",
    "def summarize_feature(df, feature, df_out, stat_cols=(10, 50), df_offset=2):\n",
    "\n",
    "    d = df[df[\"Feature\"] == feature]\n",
    "    if d.empty:\n",
    "        return df_out  \n",
    "\n",
    "    for k in stat_cols:\n",
    "        col = f\"hl_statistic_{k}\"\n",
    "        if col in d.columns:\n",
    "            df_chi = k - df_offset\n",
    "            combined_p = 1 - chi2.cdf(d[col].mean(), df_chi)\n",
    "            df_out.loc[feature, f\"hl_pvalue_combined_{k}\"] = combined_p\n",
    "\n",
    "    # --- OR summary ---\n",
    "    if \"OR\" in d.columns:\n",
    "        or_mean = d[\"OR\"].mean()\n",
    "        or_std = d[\"OR\"].std(ddof=1)\n",
    "        df_out.loc[feature, \"OR\"] = or_mean\n",
    "        df_out.loc[feature, \"2.5%\"] = or_mean - or_std\n",
    "        df_out.loc[feature, \"97.5%\"] = or_mean + or_std\n",
    "\n",
    "    # --- min/max de los IC originales (tal como lo estabas haciendo) ---\n",
    "    if \"2.5%\" in d.columns:\n",
    "        df_out.loc[feature, \"minOR\"] = d[\"2.5%\"].min()\n",
    "    if \"97.5%\" in d.columns:\n",
    "        df_out.loc[feature, \"maxOR\"] = d[\"97.5%\"].max()\n",
    "\n",
    "    return df_out\n",
    "\n",
    "\n",
    "features = [\"Mono\", \"One\", \"Two\", \"Three\", \"Total\"] \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def hosmer_lemeshow(y_true, y_prob, g):\n",
    "    hl_df = pd.DataFrame({\n",
    "        \"observed\": y_true,\n",
    "        \"predicted_probability\": y_prob\n",
    "    }).dropna()\n",
    "\n",
    "\n",
    "    hl_df[\"group\"] = pd.qcut(hl_df[\"predicted_probability\"], g, duplicates=\"drop\")\n",
    "\n",
    "    hl_table = hl_df.groupby(\"group\").apply(\n",
    "        lambda x: pd.Series({\n",
    "            \"observed\": x[\"observed\"].sum(),\n",
    "            \"expected\": x[\"predicted_probability\"].sum(),\n",
    "            \"total\": len(x)\n",
    "        })\n",
    "    )\n",
    "\n",
    "    hl_table[\"observed_neg\"] = hl_table[\"total\"] - hl_table[\"observed\"]\n",
    "    hl_table[\"expected_neg\"] = hl_table[\"total\"] - hl_table[\"expected\"]\n",
    "\n",
    "\n",
    "    hl_statistic = (\n",
    "        ((hl_table[\"observed\"] - hl_table[\"expected\"])**2) / hl_table[\"expected\"] +\n",
    "        ((hl_table[\"observed_neg\"] - hl_table[\"expected_neg\"])**2) / hl_table[\"expected_neg\"]\n",
    "    ).sum()\n",
    "\n",
    "\n",
    "    dof = hl_table.shape[0] - 2\n",
    "    p_value = 1 - chi2.cdf(hl_statistic, dof)\n",
    "\n",
    "    return hl_statistic, p_value\n",
    "\n",
    "\n",
    "\n",
    "def summarize_feature_by_covar(df, covar, feature, df_out, stat_cols=(10, 50), df_offset=2):\n",
    "    d = df[(df[\"Covar\"] == covar) & (df[\"Feature\"] == feature)]\n",
    "    if d.empty:\n",
    "        return df_out\n",
    "\n",
    "    idx = (covar, feature)\n",
    "\n",
    "    for k in stat_cols:\n",
    "        col = f\"hl_statistic_{k}\"\n",
    "        if col in d.columns:\n",
    "            df_chi = k - df_offset\n",
    "            df_out.loc[idx, f\"hl_pvalue_combined_{k}\"] = 1 - chi2.cdf(d[col].mean(), df_chi)\n",
    "\n",
    "    or_mean = d[\"OR\"].mean()\n",
    "    or_std  = d[\"OR\"].std(ddof=1)\n",
    "    df_out.loc[idx, \"OR\"] = or_mean\n",
    "    df_out.loc[idx, \"2.5%\"] = or_mean - or_std\n",
    "    df_out.loc[idx, \"97.5%\"] = or_mean + or_std\n",
    "\n",
    "    df_out.loc[idx, \"minOR\"] = d[\"2.5%\"].min()\n",
    "    df_out.loc[idx, \"maxOR\"] = d[\"97.5%\"].max()\n",
    "\n",
    "    df_out.loc[idx, \"n_iter\"] = d.shape[0]\n",
    "\n",
    "    return df_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da01889-bf76-4bb4-9e3b-de9c0d5ea14b",
   "metadata": {},
   "source": [
    "# Cross Odds ratios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794b0264-ed25-4657-8942-47b1e1e26af9",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd699022-b5ce-4098-a5c8-cef93fec309d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/BBAG-cross.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19abb9a9-c9f3-4578-a857-1a77d76b90f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data.country != 'Slovakia'].reset_index(drop =  True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f6d1fc-81a3-4ef8-9617-7ce68ed50718",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e00dd336-570a-4863-8c9c-e9aaf8cd55c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_ = ['Mono', 'One',\t'Two',\t'Three', 'Total']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43f591e1-b215-4765-b92c-30025d465209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mono'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'One'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Two'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Three'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Total'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>seed</th>\n",
       "      <th>test_size</th>\n",
       "      <th>OR</th>\n",
       "      <th>2.5%</th>\n",
       "      <th>97.5%</th>\n",
       "      <th>z</th>\n",
       "      <th>P&gt;|z|</th>\n",
       "      <th>n_train</th>\n",
       "      <th>n_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mono</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2.113399</td>\n",
       "      <td>1.993037</td>\n",
       "      <td>2.241031</td>\n",
       "      <td>25.011644</td>\n",
       "      <td>4.567023e-138</td>\n",
       "      <td>75714</td>\n",
       "      <td>84127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mono</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.119155</td>\n",
       "      <td>1.991151</td>\n",
       "      <td>2.255389</td>\n",
       "      <td>23.625299</td>\n",
       "      <td>2.118488e-123</td>\n",
       "      <td>67301</td>\n",
       "      <td>84127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mono</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.159429</td>\n",
       "      <td>2.020200</td>\n",
       "      <td>2.308253</td>\n",
       "      <td>22.639530</td>\n",
       "      <td>1.769195e-113</td>\n",
       "      <td>58888</td>\n",
       "      <td>84127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mono</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2.112583</td>\n",
       "      <td>1.992371</td>\n",
       "      <td>2.240048</td>\n",
       "      <td>25.021000</td>\n",
       "      <td>3.612590e-138</td>\n",
       "      <td>75714</td>\n",
       "      <td>84127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mono</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.138561</td>\n",
       "      <td>2.009776</td>\n",
       "      <td>2.275598</td>\n",
       "      <td>23.987021</td>\n",
       "      <td>3.798751e-127</td>\n",
       "      <td>67301</td>\n",
       "      <td>84127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1510</th>\n",
       "      <td>Total</td>\n",
       "      <td>99</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.471471</td>\n",
       "      <td>0.443068</td>\n",
       "      <td>0.501694</td>\n",
       "      <td>-23.718192</td>\n",
       "      <td>2.340645e-124</td>\n",
       "      <td>67301</td>\n",
       "      <td>84127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511</th>\n",
       "      <td>Total</td>\n",
       "      <td>99</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.466724</td>\n",
       "      <td>0.436748</td>\n",
       "      <td>0.498757</td>\n",
       "      <td>-22.499139</td>\n",
       "      <td>4.231955e-112</td>\n",
       "      <td>58888</td>\n",
       "      <td>84127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512</th>\n",
       "      <td>Total</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.470080</td>\n",
       "      <td>0.443302</td>\n",
       "      <td>0.498474</td>\n",
       "      <td>-25.225596</td>\n",
       "      <td>2.098771e-140</td>\n",
       "      <td>75714</td>\n",
       "      <td>84127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1513</th>\n",
       "      <td>Total</td>\n",
       "      <td>100</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.474066</td>\n",
       "      <td>0.445501</td>\n",
       "      <td>0.504463</td>\n",
       "      <td>-23.539730</td>\n",
       "      <td>1.599432e-122</td>\n",
       "      <td>67301</td>\n",
       "      <td>84127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1514</th>\n",
       "      <td>Total</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.472024</td>\n",
       "      <td>0.441697</td>\n",
       "      <td>0.504434</td>\n",
       "      <td>-22.157377</td>\n",
       "      <td>8.856057e-109</td>\n",
       "      <td>58888</td>\n",
       "      <td>84127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1515 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Feature  seed  test_size        OR      2.5%     97.5%          z  \\\n",
       "0       Mono     0        0.1  2.113399  1.993037  2.241031  25.011644   \n",
       "1       Mono     0        0.2  2.119155  1.991151  2.255389  23.625299   \n",
       "2       Mono     0        0.3  2.159429  2.020200  2.308253  22.639530   \n",
       "3       Mono     1        0.1  2.112583  1.992371  2.240048  25.021000   \n",
       "4       Mono     1        0.2  2.138561  2.009776  2.275598  23.987021   \n",
       "...      ...   ...        ...       ...       ...       ...        ...   \n",
       "1510   Total    99        0.2  0.471471  0.443068  0.501694 -23.718192   \n",
       "1511   Total    99        0.3  0.466724  0.436748  0.498757 -22.499139   \n",
       "1512   Total   100        0.1  0.470080  0.443302  0.498474 -25.225596   \n",
       "1513   Total   100        0.2  0.474066  0.445501  0.504463 -23.539730   \n",
       "1514   Total   100        0.3  0.472024  0.441697  0.504434 -22.157377   \n",
       "\n",
       "              P>|z|  n_train  n_total  \n",
       "0     4.567023e-138    75714    84127  \n",
       "1     2.118488e-123    67301    84127  \n",
       "2     1.769195e-113    58888    84127  \n",
       "3     3.612590e-138    75714    84127  \n",
       "4     3.798751e-127    67301    84127  \n",
       "...             ...      ...      ...  \n",
       "1510  2.340645e-124    67301    84127  \n",
       "1511  4.231955e-112    58888    84127  \n",
       "1512  2.098771e-140    75714    84127  \n",
       "1513  1.599432e-122    67301    84127  \n",
       "1514  8.856057e-109    58888    84127  \n",
       "\n",
       "[1515 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "vars_ = ['Mono', 'One', 'Two', 'Three', 'Total']\n",
    "\n",
    "# Data\n",
    "results_merge_df_all = data.copy()\n",
    "results_merge_df_all = results_merge_df_all.loc[:, ~results_merge_df_all.columns.duplicated()]\n",
    "\n",
    "# Params to iterate\n",
    "seeds = list(range(0, 101))   # 0..100 inclusive\n",
    "test_sizes = [0.1, 0.2, 0.3]\n",
    "\n",
    "rows = []\n",
    "\n",
    "for feature in vars_:\n",
    "    display(feature)\n",
    "\n",
    "    d = results_merge_df_all[[feature, 'GAP_bin']].dropna().copy()\n",
    "    y = d['GAP_bin'].astype(int)\n",
    "\n",
    "    for seed in seeds:\n",
    "        for test_size in test_sizes:\n",
    "            X = d[[feature]].astype(float)\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y, test_size=test_size, random_state=seed\n",
    "            )\n",
    "\n",
    "            scaler = MinMaxScaler(feature_range=(0.05, 0.95))\n",
    "            X_train_scaled = pd.DataFrame(\n",
    "                scaler.fit_transform(X_train),\n",
    "                columns=X_train.columns,\n",
    "                index=X_train.index\n",
    "            )\n",
    "\n",
    "            X_train_scaled['intercept'] = 1\n",
    "\n",
    "            try:\n",
    "                model = sm.Logit(y_train, X_train_scaled).fit(disp=0)\n",
    "\n",
    "                params = model.params\n",
    "                ci = model.conf_int()\n",
    "                ci_exp = np.exp(ci)\n",
    "                or_ = np.exp(params)\n",
    "\n",
    "                rows.append({\n",
    "                    \"Feature\": feature,\n",
    "                    \"seed\": seed,\n",
    "                    \"test_size\": test_size,\n",
    "                    \"OR\": float(or_[feature]),\n",
    "                    \"2.5%\": float(ci_exp.loc[feature, 0]),\n",
    "                    \"97.5%\": float(ci_exp.loc[feature, 1]),\n",
    "                    \"z\": float(model.tvalues[feature]),\n",
    "                    \"P>|z|\": float(model.pvalues[feature]),\n",
    "                    \"n_train\": int(X_train_scaled.shape[0]),\n",
    "                    \"n_total\": int(d.shape[0]),\n",
    "                })\n",
    "\n",
    "            except Exception as e:\n",
    "                rows.append({\n",
    "                    \"Feature\": feature,\n",
    "                    \"seed\": seed,\n",
    "                    \"test_size\": test_size,\n",
    "                    \"OR\": np.nan,\n",
    "                    \"2.5%\": np.nan,\n",
    "                    \"97.5%\": np.nan,\n",
    "                    \"z\": np.nan,\n",
    "                    \"P>|z|\": np.nan,\n",
    "                    \"n_train\": int(X_train.shape[0]),\n",
    "                    \"n_total\": int(d.shape[0]),\n",
    "                    \"error\": str(e),\n",
    "                })\n",
    "\n",
    "df_directions_odd = pd.DataFrame(rows)\n",
    "\n",
    "cols_first = [\"Feature\", \"seed\", \"test_size\", \"OR\", \"2.5%\", \"97.5%\", \"z\", \"P>|z|\", \"n_train\", \"n_total\"]\n",
    "other_cols = [c for c in df_directions_odd.columns if c not in cols_first]\n",
    "df_directions_odd = df_directions_odd[cols_first + other_cols]\n",
    "\n",
    "out_path = \"Results/cross/cross_OR_-removing-slovakia_seeds0-100_testsizes0.1-0.3.xlsx\"\n",
    "df_directions_odd.to_excel(out_path, index=False)\n",
    "\n",
    "df_directions_odd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c3d20d-3690-4a0f-b6c0-62278eafbba6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21b94c8-04ba-43f3-95ee-7acfbeb68e77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7020b3e-807d-4377-b8c2-3069ec04aabb",
   "metadata": {},
   "source": [
    "# Longitudinal Relative Risk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a63a23-a3c2-4f82-8e8c-d484fe5f2543",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "786fd87d-26f8-4867-8a3f-d7766a3446f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/BBAG-long.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0da3990-9b1f-4096-8ce9-d0583651194a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data.country != 'Slovakia'].reset_index(drop =  True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5847cd-fa66-410e-a105-b967923e9fdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f846c168-7c83-43b2-ba89-d18bcdfc153e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_ = ['Mono', 'One',\t'Two',\t'Three', 'Total']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46bc2bec-8700-4033-9888-be15e0e34070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mono'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'One'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Two'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Three'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Total'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>seed</th>\n",
       "      <th>test_size</th>\n",
       "      <th>RR</th>\n",
       "      <th>2.5%</th>\n",
       "      <th>97.5%</th>\n",
       "      <th>z</th>\n",
       "      <th>P&gt;|z|</th>\n",
       "      <th>n_train</th>\n",
       "      <th>n_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mono</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.423048</td>\n",
       "      <td>1.378179</td>\n",
       "      <td>1.469378</td>\n",
       "      <td>21.582878</td>\n",
       "      <td>2.601619e-103</td>\n",
       "      <td>75714</td>\n",
       "      <td>84127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mono</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.428576</td>\n",
       "      <td>1.380613</td>\n",
       "      <td>1.478205</td>\n",
       "      <td>20.470482</td>\n",
       "      <td>3.946975e-93</td>\n",
       "      <td>67301</td>\n",
       "      <td>84127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mono</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.441742</td>\n",
       "      <td>1.390146</td>\n",
       "      <td>1.495252</td>\n",
       "      <td>19.676093</td>\n",
       "      <td>3.456433e-86</td>\n",
       "      <td>58888</td>\n",
       "      <td>84127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mono</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.416826</td>\n",
       "      <td>1.372050</td>\n",
       "      <td>1.463063</td>\n",
       "      <td>21.265069</td>\n",
       "      <td>2.391411e-100</td>\n",
       "      <td>75714</td>\n",
       "      <td>84127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mono</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.422700</td>\n",
       "      <td>1.375137</td>\n",
       "      <td>1.471909</td>\n",
       "      <td>20.321654</td>\n",
       "      <td>8.274199e-92</td>\n",
       "      <td>67301</td>\n",
       "      <td>84127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1510</th>\n",
       "      <td>Total</td>\n",
       "      <td>99</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.706701</td>\n",
       "      <td>0.683054</td>\n",
       "      <td>0.731168</td>\n",
       "      <td>-19.991322</td>\n",
       "      <td>6.553582e-89</td>\n",
       "      <td>67301</td>\n",
       "      <td>84127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511</th>\n",
       "      <td>Total</td>\n",
       "      <td>99</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.703113</td>\n",
       "      <td>0.677980</td>\n",
       "      <td>0.729178</td>\n",
       "      <td>-18.965915</td>\n",
       "      <td>3.262977e-80</td>\n",
       "      <td>58888</td>\n",
       "      <td>84127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512</th>\n",
       "      <td>Total</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.698829</td>\n",
       "      <td>0.676749</td>\n",
       "      <td>0.721630</td>\n",
       "      <td>-21.876064</td>\n",
       "      <td>4.391457e-106</td>\n",
       "      <td>75714</td>\n",
       "      <td>84127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1513</th>\n",
       "      <td>Total</td>\n",
       "      <td>100</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.701342</td>\n",
       "      <td>0.677859</td>\n",
       "      <td>0.725640</td>\n",
       "      <td>-20.416035</td>\n",
       "      <td>1.204538e-92</td>\n",
       "      <td>67301</td>\n",
       "      <td>84127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1514</th>\n",
       "      <td>Total</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.703296</td>\n",
       "      <td>0.678067</td>\n",
       "      <td>0.729463</td>\n",
       "      <td>-18.883992</td>\n",
       "      <td>1.544582e-79</td>\n",
       "      <td>58888</td>\n",
       "      <td>84127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1515 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Feature  seed  test_size        RR      2.5%     97.5%          z  \\\n",
       "0       Mono     0        0.1  1.423048  1.378179  1.469378  21.582878   \n",
       "1       Mono     0        0.2  1.428576  1.380613  1.478205  20.470482   \n",
       "2       Mono     0        0.3  1.441742  1.390146  1.495252  19.676093   \n",
       "3       Mono     1        0.1  1.416826  1.372050  1.463063  21.265069   \n",
       "4       Mono     1        0.2  1.422700  1.375137  1.471909  20.321654   \n",
       "...      ...   ...        ...       ...       ...       ...        ...   \n",
       "1510   Total    99        0.2  0.706701  0.683054  0.731168 -19.991322   \n",
       "1511   Total    99        0.3  0.703113  0.677980  0.729178 -18.965915   \n",
       "1512   Total   100        0.1  0.698829  0.676749  0.721630 -21.876064   \n",
       "1513   Total   100        0.2  0.701342  0.677859  0.725640 -20.416035   \n",
       "1514   Total   100        0.3  0.703296  0.678067  0.729463 -18.883992   \n",
       "\n",
       "              P>|z|  n_train  n_total  \n",
       "0     2.601619e-103    75714    84127  \n",
       "1      3.946975e-93    67301    84127  \n",
       "2      3.456433e-86    58888    84127  \n",
       "3     2.391411e-100    75714    84127  \n",
       "4      8.274199e-92    67301    84127  \n",
       "...             ...      ...      ...  \n",
       "1510   6.553582e-89    67301    84127  \n",
       "1511   3.262977e-80    58888    84127  \n",
       "1512  4.391457e-106    75714    84127  \n",
       "1513   1.204538e-92    67301    84127  \n",
       "1514   1.544582e-79    58888    84127  \n",
       "\n",
       "[1515 rows x 10 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "vars_ = ['Mono', 'One', 'Two', 'Three', 'Total']\n",
    "\n",
    "results_merge_df_all = data.copy()\n",
    "results_merge_df_all = results_merge_df_all.loc[:, ~results_merge_df_all.columns.duplicated()]\n",
    "\n",
    "seeds = list(range(0, 101))   # 0..100 inclusive\n",
    "test_sizes = [0.1, 0.2, 0.3]\n",
    "\n",
    "rows = []\n",
    "\n",
    "for feature in vars_:\n",
    "    display(feature)\n",
    "    \n",
    "    d = results_merge_df_all[[feature, 'GAP_bin', 'delta_time']].dropna().copy()\n",
    "    y = d['GAP_bin'].astype(int)\n",
    "\n",
    "    for seed in seeds:\n",
    "        for test_size in test_sizes:\n",
    "            X = d[[feature] + ['delta_time']].astype(float)\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y, test_size=test_size, random_state=seed\n",
    "            )\n",
    "\n",
    "            scaler = MinMaxScaler(feature_range=(0.05, 0.95))\n",
    "            X_train_scaled = pd.DataFrame(\n",
    "                scaler.fit_transform(X_train),\n",
    "                columns=X_train.columns,\n",
    "                index=X_train.index\n",
    "            )\n",
    "\n",
    "            X_train_scaled['intercept'] = 1\n",
    "\n",
    "            try:\n",
    "                model = sm.GLM(y_train, X_train_scaled, family=sm.families.Binomial(link=sm.families.links.log())).fit(disp = 0)\n",
    "\n",
    "                params = model.params\n",
    "                ci = model.conf_int()\n",
    "                ci_exp = np.exp(ci)\n",
    "                rr_ = np.exp(params)\n",
    "\n",
    "                rows.append({\n",
    "                    \"Feature\": feature,\n",
    "                    \"seed\": seed,\n",
    "                    \"test_size\": test_size,\n",
    "                    \"RR\": float(rr_[feature]),\n",
    "                    \"2.5%\": float(ci_exp.loc[feature, 0]),\n",
    "                    \"97.5%\": float(ci_exp.loc[feature, 1]),\n",
    "                    \"z\": float(model.tvalues[feature]),\n",
    "                    \"P>|z|\": float(model.pvalues[feature]),\n",
    "                    \"n_train\": int(X_train_scaled.shape[0]),\n",
    "                    \"n_total\": int(d.shape[0]),\n",
    "                })\n",
    "\n",
    "            except Exception as e:\n",
    "                rows.append({\n",
    "                    \"Feature\": feature,\n",
    "                    \"seed\": seed,\n",
    "                    \"test_size\": test_size,\n",
    "                    \"RR\": np.nan,\n",
    "                    \"2.5%\": np.nan,\n",
    "                    \"97.5%\": np.nan,\n",
    "                    \"z\": np.nan,\n",
    "                    \"P>|z|\": np.nan,\n",
    "                    \"n_train\": int(X_train.shape[0]),\n",
    "                    \"n_total\": int(d.shape[0]),\n",
    "                    \"error\": str(e),\n",
    "                })\n",
    "\n",
    "df_directions_odd = pd.DataFrame(rows)\n",
    "\n",
    "cols_first = [\"Feature\", \"seed\", \"test_size\", \"RR\", \"2.5%\", \"97.5%\", \"z\", \"P>|z|\", \"n_train\", \"n_total\"]\n",
    "other_cols = [c for c in df_directions_odd.columns if c not in cols_first]\n",
    "df_directions_odd = df_directions_odd[cols_first + other_cols]\n",
    "\n",
    "out_path = \"Results/long/long_RR_-removing-slovakia_seeds0-100_testsizes0.1-0.3.xlsx\"\n",
    "df_directions_odd.to_excel(out_path, index=False)\n",
    "\n",
    "df_directions_odd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675f782e-a7f5-47e4-a6ae-5cb4b6295886",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b2f8b6-aa2c-4dfd-9bcf-470b9043d6d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

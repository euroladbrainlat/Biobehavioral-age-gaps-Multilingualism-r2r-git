{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f67a47d9-8778-4db5-94be-173846cbd6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from matplotlib.lines import Line2D\n",
    "from scipy.stats import pearsonr, gaussian_kde, linregress, ttest_ind, sem, zscore\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import percentileofscore\n",
    "from sklearn.utils.validation import check_random_state\n",
    "from math import factorial\n",
    "from more_itertools import distinct_permutations\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import linregress\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import KFold, ParameterGrid, train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import warnings\n",
    "import random\n",
    "#from torch.utils.data import SubsetRandomSampler\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from statsmodels.stats.diagnostic import linear_harvey_collier\n",
    "from scipy.stats import chi2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from colorama import Fore, Style, init\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from collections import Counter\n",
    "\n",
    "from statsmodels.stats.diagnostic import linear_harvey_collier\n",
    "from scipy.stats import chi2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from colorama import Fore, Style, init\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fabecce3-4309-4dda-8aea-2e7a0ecfa21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2\n",
    "\n",
    "def summarize_feature(df, feature, df_out, stat_cols=(10, 50), df_offset=2):\n",
    "\n",
    "    d = df[df[\"Feature\"] == feature]\n",
    "    if d.empty:\n",
    "        return df_out  \n",
    "\n",
    "    for k in stat_cols:\n",
    "        col = f\"hl_statistic_{k}\"\n",
    "        if col in d.columns:\n",
    "            df_chi = k - df_offset\n",
    "            combined_p = 1 - chi2.cdf(d[col].mean(), df_chi)\n",
    "            df_out.loc[feature, f\"hl_pvalue_combined_{k}\"] = combined_p\n",
    "\n",
    "    # --- OR summary ---\n",
    "    if \"OR\" in d.columns:\n",
    "        or_mean = d[\"OR\"].mean()\n",
    "        or_std = d[\"OR\"].std(ddof=1)\n",
    "        df_out.loc[feature, \"OR\"] = or_mean\n",
    "        df_out.loc[feature, \"2.5%\"] = or_mean - or_std\n",
    "        df_out.loc[feature, \"97.5%\"] = or_mean + or_std\n",
    "\n",
    "    # --- min/max de los IC originales (tal como lo estabas haciendo) ---\n",
    "    if \"2.5%\" in d.columns:\n",
    "        df_out.loc[feature, \"minOR\"] = d[\"2.5%\"].min()\n",
    "    if \"97.5%\" in d.columns:\n",
    "        df_out.loc[feature, \"maxOR\"] = d[\"97.5%\"].max()\n",
    "\n",
    "    return df_out\n",
    "\n",
    "\n",
    "features = [\"Mono\", \"One\", \"Two\", \"Three\", \"Total\"] \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from scipy.stats import chi2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "\n",
    "def hosmer_lemeshow(y_true, y_prob, g=10, eps=1e-12):\n",
    "\n",
    "    hl_df = pd.DataFrame({\n",
    "        \"observed\": y_true,\n",
    "        \"predicted_probability\": y_prob\n",
    "    }).dropna()\n",
    "\n",
    "    if hl_df.shape[0] < g:\n",
    "        return np.nan, np.nan\n",
    "\n",
    "    hl_df[\"group\"] = pd.qcut(hl_df[\"predicted_probability\"], g, duplicates=\"drop\")\n",
    "    hl_table = hl_df.groupby(\"group\").apply(\n",
    "        lambda x: pd.Series({\n",
    "            \"observed\": x[\"observed\"].sum(),\n",
    "            \"expected\": x[\"predicted_probability\"].sum(),\n",
    "            \"total\": len(x)\n",
    "        })\n",
    "    )\n",
    "\n",
    "    if hl_table.shape[0] < 3:\n",
    "        return np.nan, np.nan\n",
    "\n",
    "    hl_table[\"observed_neg\"] = hl_table[\"total\"] - hl_table[\"observed\"]\n",
    "    hl_table[\"expected_neg\"] = hl_table[\"total\"] - hl_table[\"expected\"]\n",
    "\n",
    "    hl_statistic = (\n",
    "        ((hl_table[\"observed\"] - hl_table[\"expected\"]) ** 2) / (hl_table[\"expected\"] + eps) +\n",
    "        ((hl_table[\"observed_neg\"] - hl_table[\"expected_neg\"]) ** 2) / (hl_table[\"expected_neg\"] + eps)\n",
    "    ).sum()\n",
    "\n",
    "    dof = hl_table.shape[0] - 2\n",
    "    p_value = 1 - chi2.cdf(hl_statistic, dof)\n",
    "\n",
    "    return hl_statistic, p_value\n",
    "\n",
    "\n",
    "\n",
    "def binarize_with_thresholds(s, low_thr, high_thr):\n",
    "    \"\"\"\n",
    "    > high_thr -> 1\n",
    "    <= low_thr -> 0\n",
    "    entre medio -> NaN\n",
    "    \"\"\"\n",
    "    return np.where(\n",
    "        s > high_thr, 1,\n",
    "        np.where(s <= low_thr, 0, np.nan)\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def summarize_feature_by_covar(df, covar, feature, df_out, stat_cols=(10, 50), df_offset=2):\n",
    "    d = df[(df[\"Covar\"] == covar) & (df[\"Feature\"] == feature)]\n",
    "    if d.empty:\n",
    "        return df_out\n",
    "\n",
    "    idx = (covar, feature)\n",
    "\n",
    "    for k in stat_cols:\n",
    "        col = f\"hl_statistic_{k}\"\n",
    "        if col in d.columns:\n",
    "            df_chi = k - df_offset\n",
    "            df_out.loc[idx, f\"hl_pvalue_combined_{k}\"] = 1 - chi2.cdf(d[col].mean(), df_chi)\n",
    "\n",
    "    or_mean = d[\"OR\"].mean()\n",
    "    or_std  = d[\"OR\"].std(ddof=1)\n",
    "    df_out.loc[idx, \"OR\"] = or_mean\n",
    "    df_out.loc[idx, \"2.5%\"] = or_mean - or_std\n",
    "    df_out.loc[idx, \"97.5%\"] = or_mean + or_std\n",
    "\n",
    "    df_out.loc[idx, \"minOR\"] = d[\"2.5%\"].min()\n",
    "    df_out.loc[idx, \"maxOR\"] = d[\"97.5%\"].max()\n",
    "\n",
    "    df_out.loc[idx, \"n_iter\"] = d.shape[0]\n",
    "\n",
    "    return df_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794b0264-ed25-4657-8942-47b1e1e26af9",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28ae4bf3-d7cb-4505-b2e5-63c1daa3e05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd699022-b5ce-4098-a5c8-cef93fec309d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet('data/BBAG-cross.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19abb9a9-c9f3-4578-a857-1a77d76b90f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data.country != 'Slovakia'].reset_index(drop =  True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95f6d1fc-81a3-4ef8-9617-7ce68ed50718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Austria': 4320,\n",
       "         'Belgium': 4942,\n",
       "         'Czechia': 5575,\n",
       "         'Switzerland': 2634,\n",
       "         'Germany': 4567,\n",
       "         'Denmark': 2609,\n",
       "         'Estonia': 7522,\n",
       "         'Spain': 4912,\n",
       "         'France': 3640,\n",
       "         'Hungary': 3010,\n",
       "         'Italy': 4541,\n",
       "         'Netherlands': 2546,\n",
       "         'Poland': 3612,\n",
       "         'Portugal': 1914,\n",
       "         'Sweden': 2792,\n",
       "         'Slovenia': 5291,\n",
       "         'Luxembourg': 2104,\n",
       "         'Greece': 2599,\n",
       "         'Croatia': 2798,\n",
       "         'Bulgaria': 1953,\n",
       "         'Cyprus': 1205,\n",
       "         'Finland': 1982,\n",
       "         'Lithuania': 2033,\n",
       "         'Latvia': 1684,\n",
       "         'Malta': 1259,\n",
       "         'Romania': 2083})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(data.country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e00dd336-570a-4863-8c9c-e9aaf8cd55c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_ = ['Mono', 'One',\t'Two',\t'Three', 'Total']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da01889-bf76-4bb4-9e3b-de9c0d5ea14b",
   "metadata": {},
   "source": [
    "# Odds ratios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0993fa9c-3a22-4278-a618-1b62601dcd75",
   "metadata": {},
   "source": [
    "## Without co-vars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4d605d-d8cc-44e2-9ada-1ef18e799242",
   "metadata": {},
   "source": [
    "### Without iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce90ad68-7cfb-4562-ac78-81e64031b55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_merge_df_all = data.copy()\n",
    "\n",
    "rows = []\n",
    "\n",
    "for i in vars_:\n",
    "\n",
    "    s = results_merge_df_all[i].dropna()\n",
    "\n",
    "    p5  = int(np.floor(np.percentile(s, 5)))\n",
    "    p25 = int(np.floor(np.percentile(s, 25)))\n",
    "    p75 = int(np.ceil(np.percentile(s, 75)))\n",
    "    p95 = int(np.ceil(np.percentile(s, 95)))\n",
    "\n",
    "    low_thresholds  = range(p5, p25)   # ej: 3..10\n",
    "    high_thresholds = range(p75, p95)  # ej: 40..55\n",
    "\n",
    "    for low_thr in low_thresholds:\n",
    "        for high_thr in high_thresholds:\n",
    "\n",
    "            tmp = results_merge_df_all.copy()\n",
    "            tmp[i] = binarize_with_thresholds(tmp[i], low_thr, high_thr)\n",
    "\n",
    "            tmp = tmp.dropna(subset=[i, \"GAP_bin\"]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "            y_ols = tmp[\"GAP_bin\"]\n",
    "            X_ols = tmp[[i]]\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X_ols, y_ols,\n",
    "                test_size=0.2,\n",
    "                random_state=42,\n",
    "                stratify=y_ols\n",
    "            )\n",
    "\n",
    "            X_train[\"intercept\"] = 1\n",
    "            X_test[\"intercept\"] = 1\n",
    "\n",
    "\n",
    "            model = sm.Logit(y_train, X_train).fit(disp=0)\n",
    "\n",
    "\n",
    "            params = model.params\n",
    "            conf = np.exp(model.conf_int())\n",
    "            conf[\"OR\"] = np.exp(params)\n",
    "            conf[\"z\"] = model.tvalues\n",
    "            conf[\"P>|z|\"] = model.pvalues\n",
    "            conf.columns = [\"2.5%\", \"97.5%\", \"OR\", \"z\", \"P>|z|\"]\n",
    "\n",
    "            df = conf.loc[i:i].copy()\n",
    "            df[\"Feature\"] = i\n",
    "            df[\"low_thr\"] = low_thr\n",
    "            df[\"high_thr\"] = high_thr\n",
    "            df[\"n_used\"] = tmp.shape[0]\n",
    "\n",
    "            rows.append(df)\n",
    "\n",
    "df_directions_odd = pd.concat(rows, axis=0).reset_index(drop=True) if rows else pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f9a4a8f-de76-4757-84a1-41708d94b959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OR</th>\n",
       "      <th>2.5%</th>\n",
       "      <th>97.5%</th>\n",
       "      <th>minOR</th>\n",
       "      <th>maxOR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mono</th>\n",
       "      <td>2.173165</td>\n",
       "      <td>1.780038</td>\n",
       "      <td>2.566293</td>\n",
       "      <td>1.488747</td>\n",
       "      <td>3.548719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>One</th>\n",
       "      <td>0.896823</td>\n",
       "      <td>0.845229</td>\n",
       "      <td>0.948418</td>\n",
       "      <td>0.708777</td>\n",
       "      <td>1.051001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Two</th>\n",
       "      <td>0.620428</td>\n",
       "      <td>0.546463</td>\n",
       "      <td>0.694394</td>\n",
       "      <td>0.439131</td>\n",
       "      <td>0.808615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Three</th>\n",
       "      <td>0.761542</td>\n",
       "      <td>0.636479</td>\n",
       "      <td>0.886605</td>\n",
       "      <td>0.507829</td>\n",
       "      <td>1.183210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>0.507716</td>\n",
       "      <td>0.457340</td>\n",
       "      <td>0.558093</td>\n",
       "      <td>0.356180</td>\n",
       "      <td>0.671706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             OR      2.5%     97.5%     minOR     maxOR\n",
       "Mono   2.173165  1.780038  2.566293  1.488747  3.548719\n",
       "One    0.896823  0.845229  0.948418  0.708777  1.051001\n",
       "Two    0.620428  0.546463  0.694394  0.439131  0.808615\n",
       "Three  0.761542  0.636479  0.886605  0.507829  1.183210\n",
       "Total  0.507716  0.457340  0.558093  0.356180  0.671706"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_directions_odd_f = pd.DataFrame()\n",
    "\n",
    "for f in vars_:\n",
    "    df_directions_odd_f = summarize_feature(df_directions_odd, f, df_directions_odd_f)\n",
    "\n",
    "df_directions_odd_f.to_excel('Results/cross/cross_OR_-removing-slovakia-binarization.xlsx')\n",
    "df_directions_odd_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510dc18a-f3fc-4911-9cb0-a0e811daca87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cdb4eea6-6a09-48ee-ae93-fd79b28fdfc1",
   "metadata": {},
   "source": [
    "### 1000-iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0cd81ab7-fdac-44d9-8aa2-3b661ee65f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_ = ['Mono', 'One', 'Two', 'Three', 'Total']\n",
    "\n",
    "results_merge_df_all = data.copy()\n",
    "\n",
    "rows = []\n",
    "\n",
    "count = 0\n",
    "\n",
    "for boosts in range(10): \n",
    "    for i in vars_:\n",
    "\n",
    "\n",
    "        a = int(np.floor(np.percentile(results_merge_df_all[i].dropna(), 5)))\n",
    "        b = int(np.floor(np.percentile(results_merge_df_all[i].dropna(), 25)))\n",
    "        c = int(np.ceil(np.percentile(results_merge_df_all[i].dropna(), 75)))\n",
    "        d = int(np.ceil(np.percentile(results_merge_df_all[i].dropna(), 95)))\n",
    "\n",
    "        low_thresholds = range(a, b)\n",
    "        high_thresholds = range(c, d)\n",
    "\n",
    "        for low_thr in low_thresholds:\n",
    "            for high_thr in high_thresholds:\n",
    "\n",
    "                tmp = results_merge_df_all.copy()\n",
    "\n",
    "                tmp[i] = binarize_with_thresholds(tmp[i], low_thr, high_thr)\n",
    "\n",
    "                tmp = tmp.dropna(subset=[i, \"GAP_bin\"]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "                y_ols = tmp[\"GAP_bin\"]\n",
    "                X_ols = tmp[[i]]\n",
    "\n",
    "                test_size = 500 / tmp.shape[0]\n",
    "\n",
    "\n",
    "                X_train, X_test, y_train, y_test = train_test_split(\n",
    "                    X_ols, y_ols,\n",
    "                    test_size=test_size,\n",
    "                    stratify=tmp[\"GAP_bin\"],\n",
    "                    random_state=boosts\n",
    "                )\n",
    "\n",
    "                X_train = X_train.copy()\n",
    "                X_test = X_test.copy()\n",
    "                X_train[\"intercept\"] = 1\n",
    "                X_test[\"intercept\"] = 1\n",
    "\n",
    "\n",
    "                model = sm.Logit(y_train, X_train).fit(disp=0)\n",
    "\n",
    "\n",
    "                params = model.params\n",
    "                conf = np.exp(model.conf_int())\n",
    "                conf[\"OR\"] = np.exp(params)\n",
    "                conf[\"z\"] = model.tvalues\n",
    "                conf[\"P>|z|\"] = model.pvalues\n",
    "                conf.columns = [\"2.5%\", \"97.5%\", \"OR\", \"z\", \"P>|z|\"]\n",
    "\n",
    "                df = conf.loc[i:i].copy()\n",
    "                df[\"Feature\"] = i\n",
    "\n",
    "                df[\"low_thr\"] = low_thr\n",
    "                df[\"high_thr\"] = high_thr\n",
    "                df[\"boosts\"] = boosts\n",
    "                df[\"n_tmp\"] = tmp.shape[0]  \n",
    "\n",
    "\n",
    "                rows.append(df)\n",
    "\n",
    "                count += 1\n",
    "\n",
    "df_directions_odd = pd.concat(rows, axis=0).reset_index(drop=True) if len(rows) else pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bad7a9a3-6ded-41c7-8389-2a5c1c488459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OR</th>\n",
       "      <th>2.5%</th>\n",
       "      <th>97.5%</th>\n",
       "      <th>minOR</th>\n",
       "      <th>maxOR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mono</th>\n",
       "      <td>2.173459</td>\n",
       "      <td>1.784604</td>\n",
       "      <td>2.562315</td>\n",
       "      <td>1.470550</td>\n",
       "      <td>3.646580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>One</th>\n",
       "      <td>0.894908</td>\n",
       "      <td>0.844584</td>\n",
       "      <td>0.945232</td>\n",
       "      <td>0.711011</td>\n",
       "      <td>1.044452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Two</th>\n",
       "      <td>0.621147</td>\n",
       "      <td>0.550883</td>\n",
       "      <td>0.691411</td>\n",
       "      <td>0.432753</td>\n",
       "      <td>0.804154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Three</th>\n",
       "      <td>0.773339</td>\n",
       "      <td>0.646089</td>\n",
       "      <td>0.900590</td>\n",
       "      <td>0.520547</td>\n",
       "      <td>1.164614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>0.508116</td>\n",
       "      <td>0.456678</td>\n",
       "      <td>0.559553</td>\n",
       "      <td>0.354053</td>\n",
       "      <td>0.680018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             OR      2.5%     97.5%     minOR     maxOR\n",
       "Mono   2.173459  1.784604  2.562315  1.470550  3.646580\n",
       "One    0.894908  0.844584  0.945232  0.711011  1.044452\n",
       "Two    0.621147  0.550883  0.691411  0.432753  0.804154\n",
       "Three  0.773339  0.646089  0.900590  0.520547  1.164614\n",
       "Total  0.508116  0.456678  0.559553  0.354053  0.680018"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_directions_odd_f = pd.DataFrame()\n",
    "\n",
    "for f in vars_:\n",
    "    df_directions_odd_f = summarize_feature(df_directions_odd, f, df_directions_odd_f)\n",
    "\n",
    "df_directions_odd_f.to_excel('Results/cross/cross_OR_-removing-slovakia-binarization-1000-iter.xlsx')\n",
    "df_directions_odd_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bdfe9540-2a54-4c73-bea0-ffbd80edb09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo total: 18 min 44.5 s\n"
     ]
    }
   ],
   "source": [
    "dt = time.perf_counter() - t0\n",
    "m, s = divmod(dt, 60)\n",
    "print(f\"Tiempo total: {int(m)} min {s:.1f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e502f2a9-6d90-447b-8330-0a8e4da01137",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

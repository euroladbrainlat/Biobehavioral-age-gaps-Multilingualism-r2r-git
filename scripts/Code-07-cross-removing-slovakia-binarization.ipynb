{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67a47d9-8778-4db5-94be-173846cbd6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from matplotlib.lines import Line2D\n",
    "from scipy.stats import pearsonr, gaussian_kde, linregress, ttest_ind, sem, zscore\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import percentileofscore\n",
    "from sklearn.utils.validation import check_random_state\n",
    "from math import factorial\n",
    "from more_itertools import distinct_permutations\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import linregress\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import KFold, ParameterGrid, train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import warnings\n",
    "import random\n",
    "#from torch.utils.data import SubsetRandomSampler\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from statsmodels.stats.diagnostic import linear_harvey_collier\n",
    "from scipy.stats import chi2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from colorama import Fore, Style, init\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from collections import Counter\n",
    "\n",
    "from statsmodels.stats.diagnostic import linear_harvey_collier\n",
    "from scipy.stats import chi2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from colorama import Fore, Style, init\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabecce3-4309-4dda-8aea-2e7a0ecfa21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2\n",
    "\n",
    "def summarize_feature(df, feature, df_out, stat_cols=(10, 50), df_offset=2):\n",
    "\n",
    "    d = df[df[\"Feature\"] == feature]\n",
    "    if d.empty:\n",
    "        return df_out  \n",
    "\n",
    "    for k in stat_cols:\n",
    "        col = f\"hl_statistic_{k}\"\n",
    "        if col in d.columns:\n",
    "            df_chi = k - df_offset\n",
    "            combined_p = 1 - chi2.cdf(d[col].mean(), df_chi)\n",
    "            df_out.loc[feature, f\"hl_pvalue_combined_{k}\"] = combined_p\n",
    "\n",
    "    # --- OR summary ---\n",
    "    if \"OR\" in d.columns:\n",
    "        or_mean = d[\"OR\"].mean()\n",
    "        or_std = d[\"OR\"].std(ddof=1)\n",
    "        df_out.loc[feature, \"OR\"] = or_mean\n",
    "        df_out.loc[feature, \"2.5%\"] = or_mean - or_std\n",
    "        df_out.loc[feature, \"97.5%\"] = or_mean + or_std\n",
    "\n",
    "\n",
    "    return df_out\n",
    "\n",
    "\n",
    "def summarize_feature_rr(df, feature, df_out, stat_cols=(10, 50), df_offset=2):\n",
    "\n",
    "    d = df[df[\"Feature\"] == feature]\n",
    "    if d.empty:\n",
    "        return df_out  \n",
    "\n",
    "    for k in stat_cols:\n",
    "        col = f\"hl_statistic_{k}\"\n",
    "        if col in d.columns:\n",
    "            df_chi = k - df_offset\n",
    "            combined_p = 1 - chi2.cdf(d[col].mean(), df_chi)\n",
    "            df_out.loc[feature, f\"hl_pvalue_combined_{k}\"] = combined_p\n",
    "\n",
    "    # --- RR summary ---\n",
    "    if \"RR\" in d.columns:\n",
    "        or_mean = d[\"RR\"].mean()\n",
    "        or_std = d[\"RR\"].std(ddof=1)\n",
    "        df_out.loc[feature, \"RR\"] = or_mean\n",
    "        df_out.loc[feature, \"2.5%\"] = or_mean - or_std\n",
    "        df_out.loc[feature, \"97.5%\"] = or_mean + or_std\n",
    "\n",
    "\n",
    "    return df_out\n",
    "\n",
    "features = [\"Mono\", \"One\", \"Two\", \"Three\", \"Total\"] \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from scipy.stats import chi2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "\n",
    "def hosmer_lemeshow(y_true, y_prob, g=10, eps=1e-12):\n",
    "\n",
    "    hl_df = pd.DataFrame({\n",
    "        \"observed\": y_true,\n",
    "        \"predicted_probability\": y_prob\n",
    "    }).dropna()\n",
    "\n",
    "    if hl_df.shape[0] < g:\n",
    "        return np.nan, np.nan\n",
    "\n",
    "    hl_df[\"group\"] = pd.qcut(hl_df[\"predicted_probability\"], g, duplicates=\"drop\")\n",
    "    hl_table = hl_df.groupby(\"group\").apply(\n",
    "        lambda x: pd.Series({\n",
    "            \"observed\": x[\"observed\"].sum(),\n",
    "            \"expected\": x[\"predicted_probability\"].sum(),\n",
    "            \"total\": len(x)\n",
    "        })\n",
    "    )\n",
    "\n",
    "    if hl_table.shape[0] < 3:\n",
    "        return np.nan, np.nan\n",
    "\n",
    "    hl_table[\"observed_neg\"] = hl_table[\"total\"] - hl_table[\"observed\"]\n",
    "    hl_table[\"expected_neg\"] = hl_table[\"total\"] - hl_table[\"expected\"]\n",
    "\n",
    "    hl_statistic = (\n",
    "        ((hl_table[\"observed\"] - hl_table[\"expected\"]) ** 2) / (hl_table[\"expected\"] + eps) +\n",
    "        ((hl_table[\"observed_neg\"] - hl_table[\"expected_neg\"]) ** 2) / (hl_table[\"expected_neg\"] + eps)\n",
    "    ).sum()\n",
    "\n",
    "    dof = hl_table.shape[0] - 2\n",
    "    p_value = 1 - chi2.cdf(hl_statistic, dof)\n",
    "\n",
    "    return hl_statistic, p_value\n",
    "\n",
    "\n",
    "\n",
    "def binarize_with_thresholds(s, low_thr, high_thr):\n",
    "    \"\"\"\n",
    "    > high_thr -> 1\n",
    "    <= low_thr -> 0\n",
    "    entre medio -> NaN\n",
    "    \"\"\"\n",
    "    return np.where(\n",
    "        s > high_thr, 1,\n",
    "        np.where(s <= low_thr, 0, np.nan)\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def summarize_feature_by_covar(df, covar, feature, df_out, stat_cols=(10, 50), df_offset=2):\n",
    "    d = df[(df[\"Covar\"] == covar) & (df[\"Feature\"] == feature)]\n",
    "    if d.empty:\n",
    "        return df_out\n",
    "\n",
    "    idx = (covar, feature)\n",
    "\n",
    "    for k in stat_cols:\n",
    "        col = f\"hl_statistic_{k}\"\n",
    "        if col in d.columns:\n",
    "            df_chi = k - df_offset\n",
    "            df_out.loc[idx, f\"hl_pvalue_combined_{k}\"] = 1 - chi2.cdf(d[col].mean(), df_chi)\n",
    "\n",
    "    or_mean = d[\"OR\"].mean()\n",
    "    or_std  = d[\"OR\"].std(ddof=1)\n",
    "    df_out.loc[idx, \"OR\"] = or_mean\n",
    "    df_out.loc[idx, \"2.5%\"] = or_mean - or_std\n",
    "    df_out.loc[idx, \"97.5%\"] = or_mean + or_std\n",
    "\n",
    "    df_out.loc[idx, \"minOR\"] = d[\"2.5%\"].min()\n",
    "    df_out.loc[idx, \"maxOR\"] = d[\"97.5%\"].max()\n",
    "\n",
    "    df_out.loc[idx, \"n_iter\"] = d.shape[0]\n",
    "\n",
    "    return df_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5317fc4e-7491-4b91-8ea8-70601d626b4b",
   "metadata": {},
   "source": [
    "## Cross-sectional OR removing Slovakia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794b0264-ed25-4657-8942-47b1e1e26af9",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ae4bf3-d7cb-4505-b2e5-63c1daa3e05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "t0 = time.perf_counter()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd699022-b5ce-4098-a5c8-cef93fec309d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/BBAG-cross.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19abb9a9-c9f3-4578-a857-1a77d76b90f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data.country != 'Slovakia'].reset_index(drop =  True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f6d1fc-81a3-4ef8-9617-7ce68ed50718",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510dc18a-f3fc-4911-9cb0-a0e811daca87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd81ab7-fdac-44d9-8aa2-3b661ee65f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_ = ['Mono', 'One', 'Two', 'Three', 'Total']\n",
    "\n",
    "results_merge_df_all = data.copy()\n",
    "\n",
    "rows = []\n",
    "\n",
    "\n",
    "\n",
    "for boosts in range(10): \n",
    "    for i in vars_:\n",
    "        count = 0\n",
    "\n",
    "        a = int(np.floor(np.percentile(results_merge_df_all[i].dropna(), 5)))\n",
    "        b = int(np.floor(np.percentile(results_merge_df_all[i].dropna(), 25)))\n",
    "        c = int(np.ceil(np.percentile(results_merge_df_all[i].dropna(), 75)))\n",
    "        d = int(np.ceil(np.percentile(results_merge_df_all[i].dropna(), 95)))\n",
    "\n",
    "        low_thresholds = range(a, b)\n",
    "        high_thresholds = range(c, d)\n",
    "\n",
    "        for low_thr in low_thresholds:\n",
    "            for high_thr in high_thresholds:\n",
    "\n",
    "                tmp = results_merge_df_all.copy()\n",
    "\n",
    "                tmp[i] = binarize_with_thresholds(tmp[i], low_thr, high_thr)\n",
    "\n",
    "                tmp = tmp.dropna(subset=[i, \"GAP_bin\"]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "                y_ols = tmp[\"GAP_bin\"]\n",
    "                X_ols = tmp[[i]]\n",
    "\n",
    "                test_size = 500 / tmp.shape[0]\n",
    "\n",
    "\n",
    "                X_train, X_test, y_train, y_test = train_test_split(\n",
    "                    X_ols, y_ols,\n",
    "                    test_size=test_size,\n",
    "                    #stratify=tmp[\"GAP_bin\"],\n",
    "                    random_state=boosts\n",
    "                )\n",
    "\n",
    "                X_train = X_train.copy()\n",
    "                X_test = X_test.copy()\n",
    "                X_train[\"intercept\"] = 1\n",
    "                X_test[\"intercept\"] = 1\n",
    "\n",
    "\n",
    "                model = sm.Logit(y_train, X_train).fit(disp=0)\n",
    "\n",
    "\n",
    "                params = model.params\n",
    "                conf = np.exp(model.conf_int())\n",
    "                conf[\"OR\"] = np.exp(params)\n",
    "                conf[\"z\"] = model.tvalues\n",
    "                conf[\"P>|z|\"] = model.pvalues\n",
    "                conf.columns = [\"2.5%\", \"97.5%\", \"OR\", \"z\", \"P>|z|\"]\n",
    "\n",
    "                df = conf.loc[i:i].copy()\n",
    "                df[\"Feature\"] = i\n",
    "\n",
    "                df[\"low_thr\"] = low_thr\n",
    "                df[\"high_thr\"] = high_thr\n",
    "                df[\"boosts\"] = boosts\n",
    "                df[\"n_tmp\"] = tmp.shape[0]  \n",
    "\n",
    "\n",
    "                rows.append(df)\n",
    "\n",
    "                count += 1\n",
    "\n",
    "df_directions_odd = pd.concat(rows, axis=0).reset_index(drop=True) if len(rows) else pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc33bed-f255-4e59-a4f3-f14aa2a35697",
   "metadata": {},
   "outputs": [],
   "source": [
    "count*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad7a9a3-6ded-41c7-8389-2a5c1c488459",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_directions_odd_f = pd.DataFrame()\n",
    "\n",
    "for f in vars_:\n",
    "    df_directions_odd_f = summarize_feature(df_directions_odd, f, df_directions_odd_f)\n",
    "\n",
    "df_directions_odd_f.to_excel('Results/cross/cross_OR_-removing-slovakia-binarization.xlsx')\n",
    "df_directions_odd_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfe9540-2a54-4c73-bea0-ffbd80edb09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = time.perf_counter() - t0\n",
    "m, s = divmod(dt, 60)\n",
    "print(f\"Tiempo total: {int(m)} min {s:.1f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6958a17-13fc-4bb3-8c86-7bce7d4cee24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4eb0a5-0c77-4b89-9059-a697516ccfc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41369012-dfb6-42a9-a30c-7e84be9a1439",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03b87384-9960-4049-9edf-2dfd7845c72a",
   "metadata": {},
   "source": [
    "## Cross-sectional OR with Slovakia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899a4871-2b08-430a-bbf0-6e707c11e2f1",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651b1592-81f0-4067-98f8-c0e8b5f0268b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "t0 = time.perf_counter()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827300d5-f4cc-42c1-819d-bc49ce703db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/BBAG-cross.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b45a34-59fe-4858-ae1a-dc32a8b407fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8129fc80-efad-407c-b2a9-28ec7f3b9ec9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6823ea2-7123-4a11-a4d3-c60cc126f338",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_ = ['Mono', 'One', 'Two', 'Three', 'Total']\n",
    "\n",
    "results_merge_df_all = data.copy()\n",
    "\n",
    "rows = []\n",
    "\n",
    "count = 0\n",
    "\n",
    "for boosts in range(10): \n",
    "    for i in vars_:\n",
    "\n",
    "\n",
    "        a = int(np.floor(np.percentile(results_merge_df_all[i].dropna(), 5)))\n",
    "        b = int(np.floor(np.percentile(results_merge_df_all[i].dropna(), 25)))\n",
    "        c = int(np.ceil(np.percentile(results_merge_df_all[i].dropna(), 75)))\n",
    "        d = int(np.ceil(np.percentile(results_merge_df_all[i].dropna(), 95)))\n",
    "\n",
    "        low_thresholds = range(a, b)\n",
    "        high_thresholds = range(c, d)\n",
    "\n",
    "        for low_thr in low_thresholds:\n",
    "            for high_thr in high_thresholds:\n",
    "\n",
    "                tmp = results_merge_df_all.copy()\n",
    "\n",
    "                tmp[i] = binarize_with_thresholds(tmp[i], low_thr, high_thr)\n",
    "\n",
    "                tmp = tmp.dropna(subset=[i, \"GAP_bin\"]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "                y_ols = tmp[\"GAP_bin\"]\n",
    "                X_ols = tmp[[i]]\n",
    "\n",
    "                test_size = 500 / tmp.shape[0]\n",
    "\n",
    "\n",
    "                X_train, X_test, y_train, y_test = train_test_split(\n",
    "                    X_ols, y_ols,\n",
    "                    test_size=test_size,\n",
    "                    #stratify=tmp[\"GAP_bin\"],\n",
    "                    random_state=boosts\n",
    "                )\n",
    "\n",
    "                X_train = X_train.copy()\n",
    "                X_test = X_test.copy()\n",
    "                X_train[\"intercept\"] = 1\n",
    "                X_test[\"intercept\"] = 1\n",
    "\n",
    "\n",
    "                model = sm.Logit(y_train, X_train).fit(disp=0)\n",
    "\n",
    "\n",
    "                params = model.params\n",
    "                conf = np.exp(model.conf_int())\n",
    "                conf[\"OR\"] = np.exp(params)\n",
    "                conf[\"z\"] = model.tvalues\n",
    "                conf[\"P>|z|\"] = model.pvalues\n",
    "                conf.columns = [\"2.5%\", \"97.5%\", \"OR\", \"z\", \"P>|z|\"]\n",
    "\n",
    "                df = conf.loc[i:i].copy()\n",
    "                df[\"Feature\"] = i\n",
    "\n",
    "                df[\"low_thr\"] = low_thr\n",
    "                df[\"high_thr\"] = high_thr\n",
    "                df[\"boosts\"] = boosts\n",
    "                df[\"n_tmp\"] = tmp.shape[0]  \n",
    "\n",
    "\n",
    "                rows.append(df)\n",
    "\n",
    "                count += 1\n",
    "\n",
    "df_directions_odd = pd.concat(rows, axis=0).reset_index(drop=True) if len(rows) else pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67191ae3-e313-4272-a3ff-a21fd7f78a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_directions_odd_f = pd.DataFrame()\n",
    "\n",
    "for f in vars_:\n",
    "    df_directions_odd_f = summarize_feature(df_directions_odd, f, df_directions_odd_f)\n",
    "\n",
    "df_directions_odd_f.to_excel('Results/cross/cross_OR_-with-slovakia-binarization.xlsx')\n",
    "df_directions_odd_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d528d18-7fc9-481d-8181-735fec9000e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = time.perf_counter() - t0\n",
    "m, s = divmod(dt, 60)\n",
    "print(f\"Tiempo total: {int(m)} min {s:.1f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c366696c-8ced-4e3d-9943-97099569b7be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d486a6-58de-4c5c-b8bc-1c460fb458b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

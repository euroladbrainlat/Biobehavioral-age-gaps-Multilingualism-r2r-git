{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f67a47d9-8778-4db5-94be-173846cbd6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from matplotlib.lines import Line2D\n",
    "from scipy.stats import pearsonr, gaussian_kde, linregress, ttest_ind, sem, zscore\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import percentileofscore\n",
    "from sklearn.utils.validation import check_random_state\n",
    "from math import factorial\n",
    "from more_itertools import distinct_permutations\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import linregress\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import KFold, ParameterGrid, train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import warnings\n",
    "import random\n",
    "#from torch.utils.data import SubsetRandomSampler\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from statsmodels.stats.diagnostic import linear_harvey_collier\n",
    "from scipy.stats import chi2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from colorama import Fore, Style, init\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from collections import Counter\n",
    "\n",
    "from statsmodels.stats.diagnostic import linear_harvey_collier\n",
    "from scipy.stats import chi2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from colorama import Fore, Style, init\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fabecce3-4309-4dda-8aea-2e7a0ecfa21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2\n",
    "\n",
    "def summarize_feature(df, feature, df_out, stat_cols=(10, 50), df_offset=2):\n",
    "\n",
    "    d = df[df[\"Feature\"] == feature]\n",
    "    if d.empty:\n",
    "        return df_out  \n",
    "\n",
    "    for k in stat_cols:\n",
    "        col = f\"hl_statistic_{k}\"\n",
    "        if col in d.columns:\n",
    "            df_chi = k - df_offset\n",
    "            combined_p = 1 - chi2.cdf(d[col].mean(), df_chi)\n",
    "            df_out.loc[feature, f\"hl_pvalue_combined_{k}\"] = combined_p\n",
    "\n",
    "    # --- OR summary ---\n",
    "    if \"OR\" in d.columns:\n",
    "        or_mean = d[\"OR\"].mean()\n",
    "        or_std = d[\"OR\"].std(ddof=1)\n",
    "        df_out.loc[feature, \"OR\"] = or_mean\n",
    "        df_out.loc[feature, \"2.5%\"] = or_mean - or_std\n",
    "        df_out.loc[feature, \"97.5%\"] = or_mean + or_std\n",
    "\n",
    "    # --- min/max de los IC originales (tal como lo estabas haciendo) ---\n",
    "    if \"2.5%\" in d.columns:\n",
    "        df_out.loc[feature, \"minOR\"] = d[\"2.5%\"].min()\n",
    "    if \"97.5%\" in d.columns:\n",
    "        df_out.loc[feature, \"maxOR\"] = d[\"97.5%\"].max()\n",
    "\n",
    "    return df_out\n",
    "\n",
    "\n",
    "features = [\"Mono\", \"One\", \"Two\", \"Three\", \"Total\"] \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def hosmer_lemeshow(y_true, y_prob, g):\n",
    "    hl_df = pd.DataFrame({\n",
    "        \"observed\": y_true,\n",
    "        \"predicted_probability\": y_prob\n",
    "    }).dropna()\n",
    "\n",
    "\n",
    "    hl_df[\"group\"] = pd.qcut(hl_df[\"predicted_probability\"], g, duplicates=\"drop\")\n",
    "\n",
    "    hl_table = hl_df.groupby(\"group\").apply(\n",
    "        lambda x: pd.Series({\n",
    "            \"observed\": x[\"observed\"].sum(),\n",
    "            \"expected\": x[\"predicted_probability\"].sum(),\n",
    "            \"total\": len(x)\n",
    "        })\n",
    "    )\n",
    "\n",
    "    hl_table[\"observed_neg\"] = hl_table[\"total\"] - hl_table[\"observed\"]\n",
    "    hl_table[\"expected_neg\"] = hl_table[\"total\"] - hl_table[\"expected\"]\n",
    "\n",
    "\n",
    "    hl_statistic = (\n",
    "        ((hl_table[\"observed\"] - hl_table[\"expected\"])**2) / hl_table[\"expected\"] +\n",
    "        ((hl_table[\"observed_neg\"] - hl_table[\"expected_neg\"])**2) / hl_table[\"expected_neg\"]\n",
    "    ).sum()\n",
    "\n",
    "\n",
    "    dof = hl_table.shape[0] - 2\n",
    "    p_value = 1 - chi2.cdf(hl_statistic, dof)\n",
    "\n",
    "    return hl_statistic, p_value\n",
    "\n",
    "\n",
    "\n",
    "def summarize_feature_by_covar(df, covar, feature, df_out, stat_cols=(10, 50), df_offset=2):\n",
    "    d = df[(df[\"Covar\"] == covar) & (df[\"Feature\"] == feature)]\n",
    "    if d.empty:\n",
    "        return df_out\n",
    "\n",
    "    idx = (covar, feature)\n",
    "\n",
    "    for k in stat_cols:\n",
    "        col = f\"hl_statistic_{k}\"\n",
    "        if col in d.columns:\n",
    "            df_chi = k - df_offset\n",
    "            df_out.loc[idx, f\"hl_pvalue_combined_{k}\"] = 1 - chi2.cdf(d[col].mean(), df_chi)\n",
    "\n",
    "    or_mean = d[\"OR\"].mean()\n",
    "    or_std  = d[\"OR\"].std(ddof=1)\n",
    "    df_out.loc[idx, \"OR\"] = or_mean\n",
    "    df_out.loc[idx, \"2.5%\"] = or_mean - or_std\n",
    "    df_out.loc[idx, \"97.5%\"] = or_mean + or_std\n",
    "\n",
    "    df_out.loc[idx, \"minOR\"] = d[\"2.5%\"].min()\n",
    "    df_out.loc[idx, \"maxOR\"] = d[\"97.5%\"].max()\n",
    "\n",
    "    df_out.loc[idx, \"n_iter\"] = d.shape[0]\n",
    "\n",
    "    return df_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794b0264-ed25-4657-8942-47b1e1e26af9",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd699022-b5ce-4098-a5c8-cef93fec309d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/BBAG-cross.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19abb9a9-c9f3-4578-a857-1a77d76b90f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e00dd336-570a-4863-8c9c-e9aaf8cd55c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_ = ['Mono', 'One',\t'Two',\t'Three', 'Total']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456b8f59-faee-49ad-9213-03aff611ab61",
   "metadata": {},
   "source": [
    "## Odd ratios with macrosocials (new vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c38ae1-0e19-4434-b75b-b284c0771fd1",
   "metadata": {},
   "source": [
    "### Without Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30247528-c620-4b41-9343-a48c44a8406b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_merge_df_all = data.copy()\n",
    "\n",
    "covar_list = (\n",
    "                'GDP_per_capita', 'GDP', 'Educ_doct', 'Educ_bach'\n",
    ")\n",
    "\n",
    "df_directions_odd_all = []\n",
    "df_directions_cov_odd_all = []\n",
    "\n",
    "for covar in covar_list:\n",
    "    for i in vars_:\n",
    "\n",
    "        c_results_merge_df_all = results_merge_df_all[[i, covar, 'GAP_bin']].dropna().reset_index(drop = True)\n",
    "        \n",
    "        y_ols = c_results_merge_df_all['GAP_bin']\n",
    "        X_ols = c_results_merge_df_all[[i, covar]]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X_ols, y_ols, test_size=0.2, random_state=42\n",
    "        )\n",
    "\n",
    "        scaler = MinMaxScaler((0.05, 0.95))\n",
    "\n",
    "        X_train_scaled = pd.DataFrame(\n",
    "            scaler.fit_transform(X_train),\n",
    "            columns=X_train.columns,\n",
    "            index=X_train.index\n",
    "        )\n",
    "        X_test_scaled = pd.DataFrame(\n",
    "            scaler.transform(X_test),\n",
    "            columns=X_test.columns,\n",
    "            index=X_test.index\n",
    "        )\n",
    "\n",
    "        X_train_scaled['intercept'] = 1\n",
    "        X_test_scaled['intercept'] = 1\n",
    "\n",
    "        model = sm.Logit(y_train, X_train_scaled).fit(disp=0)\n",
    "\n",
    "        params = model.params\n",
    "        conf = np.exp(model.conf_int())\n",
    "        conf['OR'] = np.exp(params)\n",
    "        conf['z'] = model.tvalues\n",
    "        conf['P>|z|'] = model.pvalues\n",
    "        conf.columns = ['2.5%', '97.5%', 'OR', 'z', 'P>|z|']\n",
    "\n",
    "        df_i = conf.loc[i:i].copy()\n",
    "        df_i['Feature'] = i\n",
    "        df_i['Covar'] = covar\n",
    "        df_directions_odd_all.append(df_i)\n",
    "\n",
    "        df_c = conf.loc[covar:covar].copy()\n",
    "        df_c['Feature'] = f\"{i}({covar})\"\n",
    "        df_c['Exposure'] = i          # opcional pero útil\n",
    "        df_c['Covar'] = covar\n",
    "        df_directions_cov_odd_all.append(df_c)\n",
    "\n",
    "df_directions_odd = pd.concat(df_directions_odd_all, axis=0).reset_index(drop=True)\n",
    "df_directions_cov_odd = pd.concat(df_directions_cov_odd_all, axis=0).reset_index(drop=True)\n",
    "\n",
    "#df_directions_odd, df_directions_cov_odd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "086557f3-ce36-4544-a24a-cabb3371451c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GDP_per_capita\n",
      "Results/cross/cross_OR_-with-slovakia_new-covar-GDP_per_capita.xlsx\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2.5%</th>\n",
       "      <th>97.5%</th>\n",
       "      <th>OR</th>\n",
       "      <th>z</th>\n",
       "      <th>P&gt;|z|</th>\n",
       "      <th>Feature</th>\n",
       "      <th>Covar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.791987</td>\n",
       "      <td>2.049279</td>\n",
       "      <td>1.916320</td>\n",
       "      <td>19.003325</td>\n",
       "      <td>1.600750e-80</td>\n",
       "      <td>Mono</td>\n",
       "      <td>GDP_per_capita</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.591514</td>\n",
       "      <td>0.694690</td>\n",
       "      <td>0.641030</td>\n",
       "      <td>-10.841656</td>\n",
       "      <td>2.184802e-27</td>\n",
       "      <td>One</td>\n",
       "      <td>GDP_per_capita</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.510367</td>\n",
       "      <td>0.593270</td>\n",
       "      <td>0.550259</td>\n",
       "      <td>-15.557071</td>\n",
       "      <td>1.424714e-54</td>\n",
       "      <td>Two</td>\n",
       "      <td>GDP_per_capita</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.843387</td>\n",
       "      <td>1.002564</td>\n",
       "      <td>0.919538</td>\n",
       "      <td>-1.901901</td>\n",
       "      <td>5.718411e-02</td>\n",
       "      <td>Three</td>\n",
       "      <td>GDP_per_capita</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.488009</td>\n",
       "      <td>0.558152</td>\n",
       "      <td>0.521903</td>\n",
       "      <td>-18.980274</td>\n",
       "      <td>2.482993e-80</td>\n",
       "      <td>Total</td>\n",
       "      <td>GDP_per_capita</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       2.5%     97.5%        OR          z         P>|z| Feature  \\\n",
       "0  1.791987  2.049279  1.916320  19.003325  1.600750e-80    Mono   \n",
       "1  0.591514  0.694690  0.641030 -10.841656  2.184802e-27     One   \n",
       "2  0.510367  0.593270  0.550259 -15.557071  1.424714e-54     Two   \n",
       "3  0.843387  1.002564  0.919538  -1.901901  5.718411e-02   Three   \n",
       "4  0.488009  0.558152  0.521903 -18.980274  2.482993e-80   Total   \n",
       "\n",
       "            Covar  \n",
       "0  GDP_per_capita  \n",
       "1  GDP_per_capita  \n",
       "2  GDP_per_capita  \n",
       "3  GDP_per_capita  \n",
       "4  GDP_per_capita  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GDP\n",
      "Results/cross/cross_OR_-with-slovakia_new-covar-GDP.xlsx\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2.5%</th>\n",
       "      <th>97.5%</th>\n",
       "      <th>OR</th>\n",
       "      <th>z</th>\n",
       "      <th>P&gt;|z|</th>\n",
       "      <th>Feature</th>\n",
       "      <th>Covar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.182891</td>\n",
       "      <td>2.476349</td>\n",
       "      <td>2.324995</td>\n",
       "      <td>26.220396</td>\n",
       "      <td>1.555784e-151</td>\n",
       "      <td>Mono</td>\n",
       "      <td>GDP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.742215</td>\n",
       "      <td>0.870378</td>\n",
       "      <td>0.803746</td>\n",
       "      <td>-5.376344</td>\n",
       "      <td>7.601365e-08</td>\n",
       "      <td>One</td>\n",
       "      <td>GDP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.433825</td>\n",
       "      <td>0.504123</td>\n",
       "      <td>0.467655</td>\n",
       "      <td>-19.837762</td>\n",
       "      <td>1.405782e-87</td>\n",
       "      <td>Two</td>\n",
       "      <td>GDP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.552433</td>\n",
       "      <td>0.644908</td>\n",
       "      <td>0.596882</td>\n",
       "      <td>-13.069386</td>\n",
       "      <td>4.926124e-39</td>\n",
       "      <td>Three</td>\n",
       "      <td>GDP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.403717</td>\n",
       "      <td>0.458035</td>\n",
       "      <td>0.430019</td>\n",
       "      <td>-26.206972</td>\n",
       "      <td>2.213088e-151</td>\n",
       "      <td>Total</td>\n",
       "      <td>GDP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       2.5%     97.5%        OR          z          P>|z| Feature Covar\n",
       "5  2.182891  2.476349  2.324995  26.220396  1.555784e-151    Mono   GDP\n",
       "6  0.742215  0.870378  0.803746  -5.376344   7.601365e-08     One   GDP\n",
       "7  0.433825  0.504123  0.467655 -19.837762   1.405782e-87     Two   GDP\n",
       "8  0.552433  0.644908  0.596882 -13.069386   4.926124e-39   Three   GDP\n",
       "9  0.403717  0.458035  0.430019 -26.206972  2.213088e-151   Total   GDP"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Educ_doct\n",
      "Results/cross/cross_OR_-with-slovakia_new-covar-Educ_doct.xlsx\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2.5%</th>\n",
       "      <th>97.5%</th>\n",
       "      <th>OR</th>\n",
       "      <th>z</th>\n",
       "      <th>P&gt;|z|</th>\n",
       "      <th>Feature</th>\n",
       "      <th>Covar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.870533</td>\n",
       "      <td>2.270587</td>\n",
       "      <td>2.060876</td>\n",
       "      <td>14.625381</td>\n",
       "      <td>1.934861e-48</td>\n",
       "      <td>Mono</td>\n",
       "      <td>Educ_doct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.748378</td>\n",
       "      <td>0.916165</td>\n",
       "      <td>0.828032</td>\n",
       "      <td>-3.656683</td>\n",
       "      <td>2.554997e-04</td>\n",
       "      <td>One</td>\n",
       "      <td>Educ_doct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.500896</td>\n",
       "      <td>0.610996</td>\n",
       "      <td>0.553213</td>\n",
       "      <td>-11.679575</td>\n",
       "      <td>1.621044e-31</td>\n",
       "      <td>Two</td>\n",
       "      <td>Educ_doct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.623647</td>\n",
       "      <td>0.803265</td>\n",
       "      <td>0.707781</td>\n",
       "      <td>-5.352845</td>\n",
       "      <td>8.658193e-08</td>\n",
       "      <td>Three</td>\n",
       "      <td>Educ_doct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.440220</td>\n",
       "      <td>0.534352</td>\n",
       "      <td>0.485008</td>\n",
       "      <td>-14.637343</td>\n",
       "      <td>1.622877e-48</td>\n",
       "      <td>Total</td>\n",
       "      <td>Educ_doct</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        2.5%     97.5%        OR          z         P>|z| Feature      Covar\n",
       "10  1.870533  2.270587  2.060876  14.625381  1.934861e-48    Mono  Educ_doct\n",
       "11  0.748378  0.916165  0.828032  -3.656683  2.554997e-04     One  Educ_doct\n",
       "12  0.500896  0.610996  0.553213 -11.679575  1.621044e-31     Two  Educ_doct\n",
       "13  0.623647  0.803265  0.707781  -5.352845  8.658193e-08   Three  Educ_doct\n",
       "14  0.440220  0.534352  0.485008 -14.637343  1.622877e-48   Total  Educ_doct"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Educ_bach\n",
      "Results/cross/cross_OR_-with-slovakia_new-covar-Educ_bach.xlsx\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2.5%</th>\n",
       "      <th>97.5%</th>\n",
       "      <th>OR</th>\n",
       "      <th>z</th>\n",
       "      <th>P&gt;|z|</th>\n",
       "      <th>Feature</th>\n",
       "      <th>Covar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.879422</td>\n",
       "      <td>2.260557</td>\n",
       "      <td>2.061199</td>\n",
       "      <td>15.354887</td>\n",
       "      <td>3.284798e-53</td>\n",
       "      <td>Mono</td>\n",
       "      <td>Educ_bach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.654446</td>\n",
       "      <td>0.790822</td>\n",
       "      <td>0.719410</td>\n",
       "      <td>-6.820034</td>\n",
       "      <td>9.101866e-12</td>\n",
       "      <td>One</td>\n",
       "      <td>Educ_bach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.537241</td>\n",
       "      <td>0.674306</td>\n",
       "      <td>0.601885</td>\n",
       "      <td>-8.757886</td>\n",
       "      <td>1.989467e-18</td>\n",
       "      <td>Two</td>\n",
       "      <td>Educ_bach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.712226</td>\n",
       "      <td>0.855662</td>\n",
       "      <td>0.780656</td>\n",
       "      <td>-5.290219</td>\n",
       "      <td>1.221698e-07</td>\n",
       "      <td>Three</td>\n",
       "      <td>Educ_bach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.442580</td>\n",
       "      <td>0.532320</td>\n",
       "      <td>0.485381</td>\n",
       "      <td>-15.346861</td>\n",
       "      <td>3.717443e-53</td>\n",
       "      <td>Total</td>\n",
       "      <td>Educ_bach</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        2.5%     97.5%        OR          z         P>|z| Feature      Covar\n",
       "15  1.879422  2.260557  2.061199  15.354887  3.284798e-53    Mono  Educ_bach\n",
       "16  0.654446  0.790822  0.719410  -6.820034  9.101866e-12     One  Educ_bach\n",
       "17  0.537241  0.674306  0.601885  -8.757886  1.989467e-18     Two  Educ_bach\n",
       "18  0.712226  0.855662  0.780656  -5.290219  1.221698e-07   Three  Educ_bach\n",
       "19  0.442580  0.532320  0.485381 -15.346861  3.717443e-53   Total  Educ_bach"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for covar in covar_list:\n",
    "    c_dfOR = df_directions_odd[df_directions_odd.Covar == covar]\n",
    "    c_dfOR.to_excel('Results/cross/cross_OR_-with-slovakia_new-covar-' + covar + '.xlsx')\n",
    "\n",
    "    print(covar)\n",
    "    print('Results/cross/cross_OR_-with-slovakia_new-covar-' + covar + '.xlsx')\n",
    "    display(c_dfOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4320d3b-b6c5-4dc6-bfb3-04c135d13172",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0eb54788-a8ad-4ffc-b897-df216754a1b7",
   "metadata": {},
   "source": [
    "### 1000-Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d49ea1-6e2c-4bf5-88f9-6c85d113263d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results_merge_df_all = data.copy()\n",
    "\n",
    "covar_list = (\n",
    "                'GDP_per_capita', 'GDP', 'Educ_doct', 'Educ_bach'\n",
    ")\n",
    "\n",
    "\n",
    "n_boosts = 10  #For performance reasons, the number of iterations was set to 10; however, 1,000 iterations were used for the results reported in the manuscript.”\n",
    "test_size = 500 / results_merge_df_all.shape[0]\n",
    "\n",
    "\n",
    "df_directions_odd_all = []\n",
    "df_directions_cov_all = []\n",
    "\n",
    "\n",
    "results_dict = {}  \n",
    "\n",
    "for covar in covar_list:\n",
    "\n",
    "    for boosts in range(n_boosts):\n",
    "\n",
    "        for i in vars_:\n",
    "\n",
    "            c_results_merge_df_all = results_merge_df_all[[i, covar, 'GAP_bin']].dropna().reset_index(drop = True)\n",
    "            \n",
    "            y_ols = c_results_merge_df_all['GAP_bin']\n",
    "            X_ols = c_results_merge_df_all[[i, covar]]\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X_ols, y_ols,\n",
    "                test_size=test_size,\n",
    "                stratify=y_ols,\n",
    "                random_state=boosts\n",
    "            )\n",
    "\n",
    "            scaler = MinMaxScaler((0.05, 0.95))\n",
    "\n",
    "            X_train_scaled = pd.DataFrame(\n",
    "                scaler.fit_transform(X_train),\n",
    "                columns=X_train.columns,\n",
    "                index=X_train.index\n",
    "            )\n",
    "\n",
    "            X_test_scaled = pd.DataFrame(\n",
    "                scaler.transform(X_test),\n",
    "                columns=X_test.columns,\n",
    "                index=X_test.index\n",
    "            )\n",
    "\n",
    "\n",
    "            X_train_scaled[\"intercept\"] = 1\n",
    "            X_test_scaled[\"intercept\"] = 1\n",
    "\n",
    "\n",
    "            model = sm.Logit(y_train, X_train_scaled).fit(disp=0)\n",
    "            y_test_pred = model.predict(X_test_scaled)\n",
    "\n",
    "            key_y = (covar, i, \"y\")\n",
    "            key_p = (covar, i, \"ypred\")\n",
    "            if key_y not in results_dict:\n",
    "                results_dict[key_y] = pd.Series(dtype=float)\n",
    "                results_dict[key_p] = pd.Series(dtype=float)\n",
    "\n",
    "            results_dict[key_y] = pd.concat([results_dict[key_y], y_test], axis=0)\n",
    "            results_dict[key_p] = pd.concat([results_dict[key_p], y_test_pred], axis=0)\n",
    "\n",
    "            params = model.params\n",
    "            conf = np.exp(model.conf_int())\n",
    "            conf[\"OR\"] = np.exp(params)\n",
    "            conf[\"z\"] = model.tvalues\n",
    "            conf[\"P>|z|\"] = model.pvalues\n",
    "            conf.columns = [\"2.5%\", \"97.5%\", \"OR\", \"z\", \"P>|z|\"]\n",
    "\n",
    "            hl10_stat, hl10_p = hosmer_lemeshow(y_test, y_test_pred, g=10)\n",
    "            hl50_stat, hl50_p = hosmer_lemeshow(y_test, y_test_pred, g=50)\n",
    "            hl100_stat, hl100_p = hosmer_lemeshow(y_test, y_test_pred, g=100)\n",
    "\n",
    "            df_i = conf.loc[i:i].copy()\n",
    "            df_i[\"Feature\"] = i\n",
    "            df_i[\"Covar\"] = covar\n",
    "            df_i[\"boosts\"] = boosts\n",
    "\n",
    "            df_i[\"hl_statistic_10\"] = hl10_stat\n",
    "            df_i[\"hl_pvalue_10\"] = hl10_p\n",
    "            df_i[\"hl_statistic_50\"] = hl50_stat\n",
    "            df_i[\"hl_pvalue_50\"] = hl50_p\n",
    "            df_i[\"hl_statistic_100\"] = hl100_stat\n",
    "            df_i[\"hl_pvalue_100\"] = hl100_p\n",
    "\n",
    "            df_directions_odd_all.append(df_i)\n",
    "\n",
    "            df_c = conf.loc[covar:covar].copy()\n",
    "            df_c[\"Feature\"] = i + \"(\" + covar + \")\"\n",
    "            df_c[\"Exposure\"] = i\n",
    "            df_c[\"Covar\"] = covar\n",
    "            df_c[\"boosts\"] = boosts\n",
    "\n",
    "            df_c[\"hl_statistic_10\"] = hl10_stat\n",
    "            df_c[\"hl_pvalue_10\"] = hl10_p\n",
    "            df_c[\"hl_statistic_50\"] = hl50_stat\n",
    "            df_c[\"hl_pvalue_50\"] = hl50_p\n",
    "            df_c[\"hl_statistic_100\"] = hl100_stat\n",
    "            df_c[\"hl_pvalue_100\"] = hl100_p\n",
    "\n",
    "            df_directions_cov_all.append(df_c)\n",
    "\n",
    "df_directions_odd = pd.concat(df_directions_odd_all, axis=0).reset_index(drop=True)\n",
    "df_directions_cov_odd = pd.concat(df_directions_cov_all, axis=0).reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1150ee0b-dfd8-4312-bcf9-0e3346a39a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "features = list(vars_) \n",
    "covars = df_directions_odd[\"Covar\"].dropna().unique()\n",
    "\n",
    "idx = pd.MultiIndex.from_product([covars, features], names=[\"Covar\", \"Feature\"])\n",
    "df_directions_odd_f = pd.DataFrame(index=idx)\n",
    "\n",
    "for c in covars:\n",
    "    for f in features:\n",
    "        df_directions_odd_f = summarize_feature_by_covar(\n",
    "            df_directions_odd, c, f, df_directions_odd_f,\n",
    "            stat_cols=(10, 50, 100), \n",
    "            df_offset=2\n",
    "        )\n",
    "\n",
    "df_directions_odd_f = df_directions_odd_f.reset_index()\n",
    "df_directions_odd_f;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d26e3d7-2d06-466a-85b9-bc132bad5ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for covar in covar_list:\n",
    "    c_dfOR = df_directions_odd_f[df_directions_odd_f.Covar == covar]\n",
    "    c_dfOR.to_excel('Results/cross/cross_OR_-with-slovakia_new-covar-' + covar + '-iter.xlsx')\n",
    "\n",
    "    print(covar)\n",
    "    display(c_dfOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191408f7-8236-4b97-b86c-e49d05c2705d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfe9540-2a54-4c73-bea0-ffbd80edb09d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182f4de3-acb5-448d-8eb1-5440a3775c53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

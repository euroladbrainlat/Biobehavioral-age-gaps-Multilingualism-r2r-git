{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f67a47d9-8778-4db5-94be-173846cbd6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from matplotlib.lines import Line2D\n",
    "from scipy.stats import pearsonr, gaussian_kde, linregress, ttest_ind, sem, zscore\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import percentileofscore\n",
    "from sklearn.utils.validation import check_random_state\n",
    "from math import factorial\n",
    "from more_itertools import distinct_permutations\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import linregress\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import KFold, ParameterGrid, train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import warnings\n",
    "import random\n",
    "#from torch.utils.data import SubsetRandomSampler\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from statsmodels.stats.diagnostic import linear_harvey_collier\n",
    "from scipy.stats import chi2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from colorama import Fore, Style, init\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from collections import Counter\n",
    "\n",
    "from statsmodels.stats.diagnostic import linear_harvey_collier\n",
    "from scipy.stats import chi2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from colorama import Fore, Style, init\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fabecce3-4309-4dda-8aea-2e7a0ecfa21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2\n",
    "\n",
    "def summarize_feature(df, feature, df_out, stat_cols=(10, 50), df_offset=2):\n",
    "\n",
    "    d = df[df[\"Feature\"] == feature]\n",
    "    if d.empty:\n",
    "        return df_out  \n",
    "\n",
    "    for k in stat_cols:\n",
    "        col = f\"hl_statistic_{k}\"\n",
    "        if col in d.columns:\n",
    "            df_chi = k - df_offset\n",
    "            combined_p = 1 - chi2.cdf(d[col].mean(), df_chi)\n",
    "            df_out.loc[feature, f\"hl_pvalue_combined_{k}\"] = combined_p\n",
    "\n",
    "    # --- OR summary ---\n",
    "    if \"OR\" in d.columns:\n",
    "        or_mean = d[\"OR\"].mean()\n",
    "        or_std = d[\"OR\"].std(ddof=1)\n",
    "        df_out.loc[feature, \"OR\"] = or_mean\n",
    "        df_out.loc[feature, \"2.5%\"] = or_mean - or_std\n",
    "        df_out.loc[feature, \"97.5%\"] = or_mean + or_std\n",
    "\n",
    "    # --- min/max de los IC originales (tal como lo estabas haciendo) ---\n",
    "    if \"2.5%\" in d.columns:\n",
    "        df_out.loc[feature, \"minOR\"] = d[\"2.5%\"].min()\n",
    "    if \"97.5%\" in d.columns:\n",
    "        df_out.loc[feature, \"maxOR\"] = d[\"97.5%\"].max()\n",
    "\n",
    "    return df_out\n",
    "\n",
    "\n",
    "features = [\"Mono\", \"One\", \"Two\", \"Three\", \"Total\"] \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def hosmer_lemeshow(y_true, y_prob, g):\n",
    "    hl_df = pd.DataFrame({\n",
    "        \"observed\": y_true,\n",
    "        \"predicted_probability\": y_prob\n",
    "    }).dropna()\n",
    "\n",
    "\n",
    "    hl_df[\"group\"] = pd.qcut(hl_df[\"predicted_probability\"], g, duplicates=\"drop\")\n",
    "\n",
    "    hl_table = hl_df.groupby(\"group\").apply(\n",
    "        lambda x: pd.Series({\n",
    "            \"observed\": x[\"observed\"].sum(),\n",
    "            \"expected\": x[\"predicted_probability\"].sum(),\n",
    "            \"total\": len(x)\n",
    "        })\n",
    "    )\n",
    "\n",
    "    hl_table[\"observed_neg\"] = hl_table[\"total\"] - hl_table[\"observed\"]\n",
    "    hl_table[\"expected_neg\"] = hl_table[\"total\"] - hl_table[\"expected\"]\n",
    "\n",
    "\n",
    "    hl_statistic = (\n",
    "        ((hl_table[\"observed\"] - hl_table[\"expected\"])**2) / hl_table[\"expected\"] +\n",
    "        ((hl_table[\"observed_neg\"] - hl_table[\"expected_neg\"])**2) / hl_table[\"expected_neg\"]\n",
    "    ).sum()\n",
    "\n",
    "\n",
    "    dof = hl_table.shape[0] - 2\n",
    "    p_value = 1 - chi2.cdf(hl_statistic, dof)\n",
    "\n",
    "    return hl_statistic, p_value\n",
    "\n",
    "\n",
    "\n",
    "def summarize_feature_by_covar(df, covar, feature, df_out, stat_cols=(10, 50), df_offset=2):\n",
    "    d = df[(df[\"Covar\"] == covar) & (df[\"Feature\"] == feature)]\n",
    "    if d.empty:\n",
    "        return df_out\n",
    "\n",
    "    idx = (covar, feature)\n",
    "\n",
    "    for k in stat_cols:\n",
    "        col = f\"hl_statistic_{k}\"\n",
    "        if col in d.columns:\n",
    "            df_chi = k - df_offset\n",
    "            df_out.loc[idx, f\"hl_pvalue_combined_{k}\"] = 1 - chi2.cdf(d[col].mean(), df_chi)\n",
    "\n",
    "    or_mean = d[\"OR\"].mean()\n",
    "    or_std  = d[\"OR\"].std(ddof=1)\n",
    "    df_out.loc[idx, \"OR\"] = or_mean\n",
    "    df_out.loc[idx, \"2.5%\"] = or_mean - or_std\n",
    "    df_out.loc[idx, \"97.5%\"] = or_mean + or_std\n",
    "\n",
    "    df_out.loc[idx, \"minOR\"] = d[\"2.5%\"].min()\n",
    "    df_out.loc[idx, \"maxOR\"] = d[\"97.5%\"].max()\n",
    "\n",
    "    df_out.loc[idx, \"n_iter\"] = d.shape[0]\n",
    "\n",
    "    return df_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794b0264-ed25-4657-8942-47b1e1e26af9",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28ae4bf3-d7cb-4505-b2e5-63c1daa3e05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd699022-b5ce-4098-a5c8-cef93fec309d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet('data/BBAG-cross.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19abb9a9-c9f3-4578-a857-1a77d76b90f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data.country != 'Slovakia'].reset_index(drop =  True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95f6d1fc-81a3-4ef8-9617-7ce68ed50718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Austria': 4320,\n",
       "         'Belgium': 4942,\n",
       "         'Czechia': 5575,\n",
       "         'Switzerland': 2634,\n",
       "         'Germany': 4567,\n",
       "         'Denmark': 2609,\n",
       "         'Estonia': 7522,\n",
       "         'Spain': 4912,\n",
       "         'France': 3640,\n",
       "         'Hungary': 3010,\n",
       "         'Italy': 4541,\n",
       "         'Netherlands': 2546,\n",
       "         'Poland': 3612,\n",
       "         'Portugal': 1914,\n",
       "         'Sweden': 2792,\n",
       "         'Slovenia': 5291,\n",
       "         'Luxembourg': 2104,\n",
       "         'Greece': 2599,\n",
       "         'Croatia': 2798,\n",
       "         'Bulgaria': 1953,\n",
       "         'Cyprus': 1205,\n",
       "         'Finland': 1982,\n",
       "         'Lithuania': 2033,\n",
       "         'Latvia': 1684,\n",
       "         'Malta': 1259,\n",
       "         'Romania': 2083})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(data.country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e00dd336-570a-4863-8c9c-e9aaf8cd55c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_ = ['Mono', 'One',\t'Two',\t'Three', 'Total']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3fd132d-d825-4768-9a67-4326132e3a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[vars_] = data[vars_] / 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da01889-bf76-4bb4-9e3b-de9c0d5ea14b",
   "metadata": {},
   "source": [
    "# Odds ratios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0993fa9c-3a22-4278-a618-1b62601dcd75",
   "metadata": {},
   "source": [
    "## Without co-vars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4d605d-d8cc-44e2-9ada-1ef18e799242",
   "metadata": {},
   "source": [
    "### Without iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a126aec1-9f4b-4ec6-b8c3-48b83d23372d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2.5%</th>\n",
       "      <th>97.5%</th>\n",
       "      <th>OR</th>\n",
       "      <th>z</th>\n",
       "      <th>P&gt;|z|</th>\n",
       "      <th>Feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.800749</td>\n",
       "      <td>3.371425</td>\n",
       "      <td>3.072868</td>\n",
       "      <td>23.729241</td>\n",
       "      <td>1.800084e-124</td>\n",
       "      <td>Mono</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.544988</td>\n",
       "      <td>0.710626</td>\n",
       "      <td>0.622320</td>\n",
       "      <td>-7.005826</td>\n",
       "      <td>2.455334e-12</td>\n",
       "      <td>One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.213613</td>\n",
       "      <td>0.294440</td>\n",
       "      <td>0.250791</td>\n",
       "      <td>-16.894970</td>\n",
       "      <td>4.899618e-64</td>\n",
       "      <td>Two</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.506979</td>\n",
       "      <td>0.627614</td>\n",
       "      <td>0.564081</td>\n",
       "      <td>-10.514530</td>\n",
       "      <td>7.404916e-26</td>\n",
       "      <td>Three</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.296887</td>\n",
       "      <td>0.357364</td>\n",
       "      <td>0.325725</td>\n",
       "      <td>-23.716052</td>\n",
       "      <td>2.462736e-124</td>\n",
       "      <td>Total</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       2.5%     97.5%        OR          z          P>|z| Feature\n",
       "0  2.800749  3.371425  3.072868  23.729241  1.800084e-124    Mono\n",
       "1  0.544988  0.710626  0.622320  -7.005826   2.455334e-12     One\n",
       "2  0.213613  0.294440  0.250791 -16.894970   4.899618e-64     Two\n",
       "3  0.506979  0.627614  0.564081 -10.514530   7.404916e-26   Three\n",
       "4  0.296887  0.357364  0.325725 -23.716052  2.462736e-124   Total"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_merge_df_all = data.copy()\n",
    "\n",
    "results_merge_df_all = results_merge_df_all.loc[:, ~results_merge_df_all.columns.duplicated()]\n",
    "\n",
    "df_directions_odd = pd.DataFrame()\n",
    "\n",
    "for i in vars_:\n",
    "    \n",
    "    y_ols = results_merge_df_all['GAP_bin']\n",
    "\n",
    "    \n",
    "    X_ols = results_merge_df_all[[i]]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_ols, y_ols, test_size=0.2, random_state=42)\n",
    "    \n",
    "    \n",
    "    X_train['intercept'] = 1\n",
    "    X_test['intercept'] = 1\n",
    "    \n",
    "    model = sm.Logit(y_train, X_train).fit(disp = 0)\n",
    "    \n",
    "    params = model.params\n",
    "    conf = np.exp(model.conf_int())\n",
    "    conf['OR'] = np.exp(params)\n",
    "    conf['z'] =model.tvalues\n",
    "    conf['P>|z|'] =model.pvalues\n",
    "    conf.columns = ['2.5%', '97.5%', 'OR', 'z', 'P>|z|']\n",
    "    \n",
    "    df = conf.loc[i:i]\n",
    "    df['Feature'] = i\n",
    "    df_directions_odd = pd.concat([df_directions_odd, df])\n",
    "\n",
    "df_directions_odd = df_directions_odd.reset_index(drop=True)\n",
    "\n",
    "df_directions_odd.to_excel('Results/cross/cross_OR_-removing-slovakia-proportions.xlsx')\n",
    "df_directions_odd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb4eea6-6a09-48ee-ae93-fd79b28fdfc1",
   "metadata": {},
   "source": [
    "### 1000-iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cd81ab7-fdac-44d9-8aa2-3b661ee65f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "count = 0\n",
    "\n",
    "results_dict = {}\n",
    "for i in vars_:\n",
    "    results_dict[i + \"_y\"] = pd.Series(dtype=float)\n",
    "    results_dict[i + \"_ypred\"] = pd.Series(dtype=float)\n",
    "\n",
    "results_merge_df_all = data.copy()\n",
    "results_merge_df_all.dropna(subset=vars_ + [\"GAP_bin\"], inplace=True)\n",
    "results_merge_df_all.reset_index(inplace=True, drop=True)\n",
    "\n",
    "df_directions_odd = pd.DataFrame()\n",
    "\n",
    "n_boosts = 10  \n",
    "test_size = 500 / results_merge_df_all.shape[0]\n",
    "\n",
    "for boosts in range(n_boosts):\n",
    "    for i in vars_:\n",
    "\n",
    "        y_ols = results_merge_df_all[\"GAP_bin\"]\n",
    "        X_ols = results_merge_df_all[[i]]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X_ols, y_ols,\n",
    "            test_size=test_size,\n",
    "            stratify=results_merge_df_all[\"GAP_bin\"],\n",
    "            random_state=boosts\n",
    "        )\n",
    "\n",
    "        \n",
    "        X_train[\"intercept\"] = 1\n",
    "        X_test[\"intercept\"] = 1\n",
    "\n",
    "\n",
    "        model = sm.Logit(y_train, X_train).fit(disp=0)\n",
    "\n",
    "\n",
    "        y_test_pred = model.predict(X_test)\n",
    "\n",
    "        results_dict[i + \"_y\"] = pd.concat([results_dict[i + \"_y\"], y_test], axis=0)\n",
    "        results_dict[i + \"_ypred\"] = pd.concat([results_dict[i + \"_ypred\"], y_test_pred], axis=0)\n",
    "\n",
    "        params = model.params\n",
    "        conf = np.exp(model.conf_int())\n",
    "        conf[\"OR\"] = np.exp(params)\n",
    "        conf[\"z\"] = model.tvalues\n",
    "        conf[\"P>|z|\"] = model.pvalues\n",
    "        conf.columns = [\"2.5%\", \"97.5%\", \"OR\", \"z\", \"P>|z|\"]\n",
    "\n",
    "        df = conf.loc[i:i].copy()\n",
    "        df[\"Feature\"] = i\n",
    "\n",
    "        hl10_stat, hl10_p = hosmer_lemeshow(y_test, y_test_pred, g=10)\n",
    "        hl50_stat, hl50_p = hosmer_lemeshow(y_test, y_test_pred, g=50)\n",
    "        hl100_stat, hl100_p = hosmer_lemeshow(y_test, y_test_pred, g=100)\n",
    "\n",
    "        df[\"hl_statistic_10\"] = hl10_stat\n",
    "        df[\"hl_pvalue_10\"] = hl10_p\n",
    "\n",
    "        df[\"hl_statistic_50\"] = hl50_stat\n",
    "        df[\"hl_pvalue_50\"] = hl50_p\n",
    "\n",
    "        df[\"hl_statistic_100\"] = hl100_stat\n",
    "        df[\"hl_pvalue_100\"] = hl100_p\n",
    "\n",
    "        df_directions_odd = pd.concat([df_directions_odd, df], axis=0)\n",
    "\n",
    "    df_directions_odd = df_directions_odd.reset_index(drop=True)\n",
    "\n",
    "df_directions_odd;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bad7a9a3-6ded-41c7-8389-2a5c1c488459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hl_pvalue_combined_10</th>\n",
       "      <th>hl_pvalue_combined_50</th>\n",
       "      <th>hl_pvalue_combined_100</th>\n",
       "      <th>OR</th>\n",
       "      <th>2.5%</th>\n",
       "      <th>97.5%</th>\n",
       "      <th>minOR</th>\n",
       "      <th>maxOR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mono</th>\n",
       "      <td>0.297950</td>\n",
       "      <td>0.400736</td>\n",
       "      <td>0.993578</td>\n",
       "      <td>3.096315</td>\n",
       "      <td>3.090437</td>\n",
       "      <td>3.102192</td>\n",
       "      <td>2.838623</td>\n",
       "      <td>3.373420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>One</th>\n",
       "      <td>0.144573</td>\n",
       "      <td>0.298007</td>\n",
       "      <td>0.988340</td>\n",
       "      <td>0.622593</td>\n",
       "      <td>0.619750</td>\n",
       "      <td>0.625435</td>\n",
       "      <td>0.549032</td>\n",
       "      <td>0.708016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Two</th>\n",
       "      <td>0.158351</td>\n",
       "      <td>0.392823</td>\n",
       "      <td>0.996717</td>\n",
       "      <td>0.259275</td>\n",
       "      <td>0.258038</td>\n",
       "      <td>0.260512</td>\n",
       "      <td>0.223107</td>\n",
       "      <td>0.301160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Three</th>\n",
       "      <td>0.097559</td>\n",
       "      <td>0.460489</td>\n",
       "      <td>0.994873</td>\n",
       "      <td>0.550249</td>\n",
       "      <td>0.548614</td>\n",
       "      <td>0.551883</td>\n",
       "      <td>0.496886</td>\n",
       "      <td>0.607950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>0.304208</td>\n",
       "      <td>0.380079</td>\n",
       "      <td>0.994973</td>\n",
       "      <td>0.323209</td>\n",
       "      <td>0.322595</td>\n",
       "      <td>0.323824</td>\n",
       "      <td>0.296661</td>\n",
       "      <td>0.352540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       hl_pvalue_combined_10  hl_pvalue_combined_50  hl_pvalue_combined_100  \\\n",
       "Mono                0.297950               0.400736                0.993578   \n",
       "One                 0.144573               0.298007                0.988340   \n",
       "Two                 0.158351               0.392823                0.996717   \n",
       "Three               0.097559               0.460489                0.994873   \n",
       "Total               0.304208               0.380079                0.994973   \n",
       "\n",
       "             OR      2.5%     97.5%     minOR     maxOR  \n",
       "Mono   3.096315  3.090437  3.102192  2.838623  3.373420  \n",
       "One    0.622593  0.619750  0.625435  0.549032  0.708016  \n",
       "Two    0.259275  0.258038  0.260512  0.223107  0.301160  \n",
       "Three  0.550249  0.548614  0.551883  0.496886  0.607950  \n",
       "Total  0.323209  0.322595  0.323824  0.296661  0.352540  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_directions_odd_f = pd.DataFrame()\n",
    "\n",
    "for f in vars_:\n",
    "    df_directions_odd_f = summarize_feature(df_directions_odd, f, df_directions_odd_f, stat_cols=(10, 50, 100))\n",
    "\n",
    "df_directions_odd_f.to_excel('Results/cross/cross_OR_-removing-slovakia-proportions-1000-iter.xlsx')\n",
    "df_directions_odd_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc45dbb7-5acb-493a-b814-af53e9c919df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdfe9540-2a54-4c73-bea0-ffbd80edb09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo total: 0 min 14.7 s\n"
     ]
    }
   ],
   "source": [
    "dt = time.perf_counter() - t0\n",
    "m, s = divmod(dt, 60)\n",
    "print(f\"Tiempo total: {int(m)} min {s:.1f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9713800c-8ecd-47cc-a1b2-c752797506e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

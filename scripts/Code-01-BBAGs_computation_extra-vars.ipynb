{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ca66e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import math\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import scipy\n",
    "from sklearn import metrics\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from scipy.stats import linregress\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7ab64c-d041-4e56-9164-76363c16e67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_coef(coef_df_all, results_labels_df_all, title = ''):\n",
    "\n",
    "    df = coef_df_all.iloc[1::, 0:2].sort_values(by='Estimate mean', ascending=False)\n",
    "    \n",
    "    colors_palette = get_bar_colors(df.reset_index().rename(columns={'index':'Features'}), X_cat_)\n",
    "    sns.barplot(x='Estimate mean', y=df.index, data=df, palette=colors_palette, orient='h')\n",
    "    plt.xlabel('Estimate mean')\n",
    "    plt.ylabel('Variable')\n",
    "    plt.xlim([0, 0.55])\n",
    "    \n",
    "    \n",
    "    r2 = np.round(coef_df_all.loc['_intercept', 'R2'],2)\n",
    "    f2 = np.round(coef_df_all.loc['_intercept', 'F2'],2)\n",
    "    rmse = np.round(coef_df_all.loc['_intercept', 'rmse'],2)\n",
    "    mde = np.round(coef_df_all.loc['_intercept', 'MDE'],2)\n",
    "    mae = np.round(coef_df_all.loc['_intercept', 'MAE'],2)\n",
    "    \n",
    "    y_true = results_labels_df_all['y_labels']\n",
    "    y_pred = results_labels_df_all['y_pred']\n",
    "    \n",
    "    correlacion, p_value = pearsonr(y_true, y_pred)\n",
    "    \n",
    "    \n",
    "    plt.text( 0.23, df.shape[0]-6, r'$R^{2}$: ' + str(np.round(r2, 2)), va='center', ha='left')\n",
    "    plt.text( 0.23, df.shape[0]-5, r'$F^{2}$: ' + str(np.round(f2, 2)), va='center', ha='left')\n",
    "    plt.text( 0.23, df.shape[0]-4, f'corr: {correlacion:.2f}', va='center', ha='left')\n",
    "    plt.text( 0.23, df.shape[0]-3, f'RMSE: {rmse:.2f}', va='center', ha='left')\n",
    "    plt.text( 0.23, df.shape[0]-2, f'MDE: {mde:.2f}', va='center', ha='left')\n",
    "    plt.text( 0.23, df.shape[0]-1, f'MAE: {mae:.2f}', va='center', ha='left')\n",
    "\n",
    "    plt.title(title)\n",
    "\n",
    "\n",
    "def plot_coef_v01(coef_df_for_plot, results_labels_df_for_plot, df_directions_for_plot):\n",
    "\n",
    "    df_directions_for_plot = df_directions_for_plot.set_index('index')\n",
    "    list_coef = list(coef_df_for_plot.index)\n",
    "    list_coef.remove('_intercept')\n",
    "    coef_df_for_orig = coef_df_for_plot.copy()\n",
    "    coef_df_for_plot['coef_sign'] = 0\n",
    "    \n",
    "    for i in list_coef:\n",
    "        sign =  df_directions_for_plot.loc[i, 'coef']\n",
    "        if(sign<0):\n",
    "            sign = -1\n",
    "        else:\n",
    "            sign = 1\n",
    "    \n",
    "        coef_df_for_plot.loc[i, 'coef_sign'] = coef_df_for_plot.loc[i, 'Estimate mean']*sign\n",
    "    \n",
    "    coef_df_for_plot['color'] = coef_df_for_plot['coef_sign'].apply(lambda x: 'red' if x > 0 else 'blue')\n",
    "    \n",
    "    coef_df_for_plot_sort = coef_df_for_plot.iloc[1::, :].sort_values(by='Estimate mean', ascending=False)\n",
    "    coef_df_for_plot_sort = coef_df_for_plot_sort[['Estimate mean', 'Estimate std', 'coef_sign', 'color']]\n",
    "    coef_df_for_plot_sort.reset_index(inplace = True)\n",
    "    \n",
    "\n",
    "    if(coef_df_for_plot_sort.loc[0, 'color'] == 'blue'):\n",
    "        sns.barplot(x='coef_sign', y='index', data=coef_df_for_plot_sort, hue='color', dodge=False, palette=['royalblue', 'firebrick'], orient='h' ,legend=False)\n",
    "    else:\n",
    "        sns.barplot(x='coef_sign', y='index', data=coef_df_for_plot_sort, hue='color', dodge=False, palette=['firebrick', 'royalblue'], orient='h' ,legend=False)\n",
    "        \n",
    "    plt.axvline(x=0, color='black', linestyle='--', linewidth=1)\n",
    "    plt.xlim([-0.3, 0.3])\n",
    "    plt.xlabel('Features importance')\n",
    "    plt.ylabel('Features')\n",
    "    \n",
    "    r2 = np.round(coef_df_for_orig.loc['_intercept', 'R2'],4)\n",
    "    f2 = np.round(coef_df_for_orig.loc['_intercept', 'F2'],4)\n",
    "    rmse = np.round(coef_df_for_orig.loc['_intercept', 'rmse'],4)\n",
    "    try:\n",
    "        mde = np.round(coef_df_for_orig.loc['_intercept', 'MDE'],4)\n",
    "    except:\n",
    "        mde = 0\n",
    "    mae = np.round(coef_df_for_orig.loc['_intercept', 'MAE'],4)\n",
    "    \n",
    "    y_true = results_labels_df_for_plot['y_labels']\n",
    "    y_pred = results_labels_df_for_plot['y_pred']\n",
    "    \n",
    "    correlacion, p_value = pearsonr(y_true, y_pred)\n",
    "    \n",
    "    plt.title(r'$R^{2}$: ' + str(np.round(r2, 4)) + r'   $F^{2}$: ' + str(np.round(f2, 4)) + f'   $r$: {correlacion:.4f}' + f'\\nRMSE: {rmse:.4f}' + f'   MDE: {mde:.4f}'+ f'   MAE: {mae:.4f}');\n",
    "    \n",
    "    plt.text( -0.20, 10, 'Protected\\nFactors', va='center', ha='center', color='blue')\n",
    "    plt.text( 0.20, 10, 'Risk\\nFactors', va='center', ha='center', color='red')\n",
    "\n",
    "    return coef_df_for_plot_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65af5cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_directional_accuracy(y_true, y_pred):\n",
    "    \n",
    "    differences = np.array(y_pred) - np.array(y_true) \n",
    "    signs = np.sign(differences)\n",
    "    mde = np.mean(signs)\n",
    "    return mde\n",
    "\n",
    "def mean_absolute_error(y_true, y_pred):\n",
    "\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    absolute_errors = np.abs(y_pred - y_true)\n",
    "    mae = np.mean(absolute_errors)\n",
    "    \n",
    "    return mae\n",
    "\n",
    "def coef_pval(coef_array_mean_, X_, y_, y_p):\n",
    "\n",
    "    n = X_.shape[0]\n",
    "    t = coef_tval(coef_array_mean_, X_, y_, y_p)\n",
    "    p = 2 * (1 - scipy.stats.t.cdf(abs(t), n - 1))\n",
    "    return p\n",
    "\n",
    "\n",
    "def coef_tval(coef_array_mean_, X_, y_, y_p):\n",
    "    \n",
    "    '''\n",
    "        coef_tval for OLS of statsmodels\n",
    "    '''\n",
    "    \n",
    "    a = np.array(coef_array_mean_[0][0]/ coef_se(X_, y_, y_p)[0])\n",
    "    b = np.array(coef_array_mean_[1::].flatten() / coef_se(X_, y_, y_p)[1:])\n",
    "    return np.append(a, b)\n",
    "\n",
    "\n",
    "def coef_se(X_, y_, y_p):\n",
    "    \n",
    "    '''\n",
    "        coef_se for OLS of statsmodels\n",
    "    '''\n",
    "    n = X_.shape[0]\n",
    "    \n",
    "    X1 = np.hstack((np.ones((n, 1)), np.matrix(X_)))\n",
    "    se_matrix = scipy.linalg.sqrtm(\n",
    "        metrics.mean_squared_error(y_, y_p) *\n",
    "        np.linalg.inv(X1.T * X1)\n",
    "    )\n",
    "    return np.diagonal(se_matrix)\n",
    "\n",
    "def directional_accuracy(predicted_values, true_values):\n",
    "\n",
    "    predicted_values = np.array(predicted_values)\n",
    "    true_values = np.array(true_values)    \n",
    "\n",
    "    difference_direction = np.sign(predicted_values - true_values)    \n",
    "    correct_direction_count = np.sum(difference_direction == 1) + np.sum(difference_direction == -1)\n",
    "    \n",
    "    directional_accuracy_score = correct_direction_count / len(predicted_values)\n",
    "    \n",
    "    return directional_accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from statsmodels.api import GLM\n",
    "from statsmodels.api import families\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297ceac0-5baa-45a0-a30c-9789a0be7731",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from scipy.stats import linregress\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import shap\n",
    "import warnings\n",
    "import scipy\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "def mean_directional_accuracy_test(y_true, y_pred):\n",
    "\n",
    "    try:\n",
    "        return np.mean(np.sign(y_true[1:] - y_true[:-1]) == np.sign(y_pred[1:] - y_pred[:-1]))\n",
    "    except:\n",
    "        differences = np.array(y_pred) - np.array(y_true) \n",
    "        signs = np.sign(differences)\n",
    "        mde = np.mean(signs)\n",
    "        return mde\n",
    "        \n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from scipy.stats import linregress\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import shap\n",
    "import warnings\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer\n",
    "\n",
    "def Regression_GBR_nested(X, y, outer_splits=10, inner_splits=5, shaps_comp=False):\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    scaler = MinMaxScaler((0.05, 0.95))\n",
    "\n",
    "    outer_cv = KFold(n_splits=outer_splits, shuffle=True, random_state=42)\n",
    "    param_grid = {\n",
    "        'n_estimators': Integer(50, 500),          # Número de árboles\n",
    "        'learning_rate': Real(0.01, 0.5, prior='log-uniform'),  # Tasa de aprendizaje\n",
    "        'max_depth': Integer(1, 5),               # Profundidad máxima de los árboles\n",
    "        'min_samples_split': Integer(2, 10),       # Mínimo de muestras para dividir un nodo\n",
    "        'min_samples_leaf': Integer(1, 10),        # Mínimo de muestras en una hoja\n",
    "    }\n",
    "\n",
    "    y_labels = []\n",
    "    y_predicts = []\n",
    "    r_squared_l = []\n",
    "    mse_l = []\n",
    "    rmse_l = []\n",
    "\n",
    "    results_labels_df = pd.DataFrame(columns=['y_labels', 'y_pred', 'GAP', 'GAP_corrected', 'ID'])\n",
    "\n",
    "    coef_array = np.zeros([X.shape[1] + 1, outer_splits])\n",
    "    lista_vars = list(X.columns)\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(outer_cv.split(X)):\n",
    "\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "\n",
    "        scaling_data = scaler.fit_transform(X_train)\n",
    "        X_train = pd.DataFrame(scaling_data, columns= X_train.columns, index = X_train.index)\n",
    "\n",
    "        scaling_data = scaler.transform(X_test)\n",
    "        X_test = pd.DataFrame(scaling_data, columns= X_test.columns, index = X_test.index)\n",
    "        \n",
    "        model = GradientBoostingRegressor(random_state=42)\n",
    "        inner_cv = KFold(n_splits=inner_splits, shuffle=True, random_state=42)\n",
    "        \n",
    "        bayes_search = BayesSearchCV(\n",
    "            estimator=model,\n",
    "            search_spaces=param_grid,\n",
    "            n_iter=3,              \n",
    "            scoring='r2',  \n",
    "            cv=inner_cv,                   \n",
    "            n_jobs=-1,             \n",
    "            random_state=42\n",
    "        )\n",
    "        bayes_search.fit(X_train, y_train)\n",
    "\n",
    "        best_model = bayes_search.best_estimator_\n",
    "\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        gap_test = y_pred - y_test\n",
    "        gap_train = best_model.predict(X_train) - y_train\n",
    "\n",
    "        slope, intercept, _, _, _ = linregress(y_train, gap_train)\n",
    "        corrected_gap = gap_test - (slope * y_test + intercept)\n",
    "\n",
    "        result = np.column_stack((y_test, y_pred, gap_test, corrected_gap))\n",
    "        temp_df = pd.DataFrame(result, columns=['y_labels', 'y_pred', 'GAP', 'GAP_corrected'])\n",
    "        temp_df['ID'] = X_test.index\n",
    "        results_labels_df = pd.concat([results_labels_df, temp_df], ignore_index=True)\n",
    "\n",
    "        y_labels.extend(y_test)\n",
    "        y_predicts.extend(y_pred)\n",
    "\n",
    "        r_squared_l.append(r2_score(y_test, y_pred))\n",
    "        mse_l.append(mean_squared_error(y_test, y_pred))\n",
    "        rmse_l.append(math.sqrt(mse_l[-1]))\n",
    "\n",
    "        coef_array[0, fold] = np.nan\n",
    "        coef_array[1:, fold] = best_model.feature_importances_\n",
    "\n",
    "    # Métricas finales\n",
    "    y_labels = np.array(y_labels)\n",
    "    y_predicts = np.array(y_predicts)\n",
    "\n",
    "    r_squared = r2_score(y_labels, y_predicts)\n",
    "    r_squared_ = np.mean(r_squared_l)\n",
    "    n = len(y_labels)\n",
    "    p = X.shape[1]\n",
    "    k = p - 1\n",
    "\n",
    "    r_squared_adj = 1 - (1 - r_squared) * (n - 1) / (n - k - 1)\n",
    "    mse = np.mean(mse_l)\n",
    "    rmse = np.mean(rmse_l)\n",
    "    mae = mean_absolute_error(y_labels, y_predicts)\n",
    "    F = (r_squared / p) / ((1 - r_squared) / (n - p - 1))\n",
    "    p_value = np.round(scipy.stats.f.sf(F, n, (n - p - 1)), 15)\n",
    "    F2 = r_squared / (1 - r_squared)\n",
    "\n",
    "    # Coeficientes medios\n",
    "    coef_df = pd.DataFrame(index=['_intercept'] + lista_vars,\n",
    "                           columns=['Estimate mean', 'Estimate std', 't value', 'p value'])\n",
    "\n",
    "    coef_df['Estimate mean'] = coef_array.mean(axis=1)\n",
    "    coef_df['Estimate std'] = coef_array.std(axis=1)\n",
    "    #coef_df['t value'] = coef_tval(coef_array.mean(axis=1), X, y_labels, y_predicts)\n",
    "    #coef_df['p value'] = coef_pval(coef_array.mean(axis=1), X, y_labels, y_predicts)\n",
    "\n",
    "    coef_df.loc['_intercept', 'R2'] = r_squared\n",
    "    coef_df.loc['_intercept', 'R2 adj'] = r_squared_adj\n",
    "    coef_df.loc['_intercept', 'R2 [+-]'] = np.std(r_squared_l)\n",
    "    coef_df.loc['_intercept', 'F2'] = F2\n",
    "    coef_df.loc['_intercept', 'mse'] = mse\n",
    "    coef_df.loc['_intercept', 'mse [+-]'] = np.std(mse_l)\n",
    "    coef_df.loc['_intercept', 'rmse'] = rmse\n",
    "    coef_df.loc['_intercept', 'rmse [+-]'] = np.std(rmse_l)\n",
    "    coef_df.loc['_intercept', 'outcome var'] = np.var(y)\n",
    "    coef_df.loc['_intercept', 'F'] = F\n",
    "    coef_df.loc['_intercept', 'F-p_value'] = p_value\n",
    "    coef_df.loc['_intercept', 'MDE'] = mean_directional_accuracy(y_labels, y_predicts)\n",
    "    coef_df.loc['_intercept', 'MAE'] = mae\n",
    "\n",
    "    results_labels_df['y_pred_corrected'] = results_labels_df['y_labels'] + results_labels_df['GAP_corrected']\n",
    "    results_labels_df = results_labels_df[['ID','y_labels', 'y_pred', 'GAP', 'GAP_corrected', 'y_pred_corrected']]\n",
    "\n",
    "    if shaps_comp:\n",
    "        explainer = shap.Explainer(best_model, X)\n",
    "        return [coef_df, r_squared_, results_labels_df, explainer]\n",
    "    else:\n",
    "        return [coef_df, r_squared_, results_labels_df]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3358e4-2a3a-4eb6-88eb-4dfb93d92c90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143624bd-8db9-47ae-aa7e-a206d3bb31d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36bd6208-8a37-42c1-bbe5-4a35069a275e",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd47e31-2cf7-42a0-8a37-77adef32af1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/BBAG-exta-vars.csv', index_col= 0)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0886f6f-ef46-4536-baf2-498d524e6b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_list = ['Sex_1F_2M',\n",
    "              'Education',\n",
    "              'Barthel',\n",
    "              'Diabetes_1Y_0N',\n",
    "              'Hypertension_1Y_0N',\n",
    "              'Heart_Disease_1Y_0N',\n",
    "              'Physical_activity_1Y_0N',\n",
    "              'Cognition',\n",
    "              'Weight_problems_v02_1Y_0N',\n",
    "              'Well_being_domain',\n",
    "              'Sleep_problems_1Y_0N',\n",
    "              'Audition_problems', \n",
    "              'Vision_problems', \n",
    "              'Alcohol_consumption_1Y_0N']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967c3910-544a-4c9a-b1a3-d951346b2843",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vars_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1635df-753a-4c3a-a2c6-7994cedef782",
   "metadata": {},
   "source": [
    "## BBAG model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2bf247-342e-4239-ba5a-7d5a2c88e125",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = data[vars_list]\n",
    "y1 = data['Age']\n",
    "\n",
    "\n",
    "[coef_df_, r_squared_, results_labels_df_] = Regression_GBR_nested(X1, y1, outer_splits=10, inner_splits=5, shaps_comp=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03482388-40ef-460a-b9fc-45a38b166166",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(coef_df_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14de6350-107b-4fe2-954b-e8a6039d227e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_GB = data.copy()\n",
    "results_GB.index.name = \"ID\"\n",
    "\n",
    "results_GB_ = results_labels_df_.set_index('ID')\n",
    "final_dataframe = pd.merge(results_GB_, results_GB, on='ID', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0a0e6c-51e5-4906-b6b8-4816069d216e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataframe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2334586b-cfb8-45ab-8cbf-2fdd0749c683",
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_dataframe.to_csv('name.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c0b4b4-efbb-4fc5-b8cd-43ec24d4afeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
